# 8 神经网络（入门）

本章将学习一种叫做神经网络的机器学习算法。

## 8.1 非线性假设

我们已经有线性回归、逻辑回归这两种算法了，为什么还要研究神经网络呢？下面通过一个例子进行阐述。

![image-20210925105038118](E:\md笔记\PyTorch\images\image-20210925105038118.png)

假如有一个监督学习分类问题，它的训练集如上图所示。如果利用逻辑回归来解决这个问题，则可以构造一个包含很多非线性的逻辑回归函数，如上图右侧所示【$g$表示$Sigmoid$函数】。当多项式数足够多时，那么可能你就能得到一条合适的决策边界。如果只有两个特征$x_1$、$x_2$，那么这个方法很合适，因为你可以把$x_1$、$x_2$的所有组合都包含到多项式中。但当特征数远远不止两个时，这些特征的组合项将会非常多。比如我们有100个特征，即便我们只采用两两特征的组合$(x_1x_2+x_1x_3+x_1x_4+...+x_2x_3+x_2x_4+...+x_{99}x_{100})$，我们也会有接近5000个组合而成的特征。这对于一般的逻辑回归来说需要计算的特征太多了；如果现在假设包括立方项或者三次项，例如$x_1x_2x_3+x_1x_2x_4+...$，可以想象，类似的三次项会有很多很多，事实上，三次项的个数是$n^3$的数量级，因此当$n=100$时，大概有17000个三次项。将这些高阶多项式数包括到特征里会使特征空间急剧膨胀，当特征数$n$很大时，建立非线性分类器并不是一个好做法。

假设你想要训练一个分类器，来检测图片上是否是汽车。当人眼一目了然的看到图片的物品时，计算机实际上看到的是一个个数据矩阵（表示像素强度值的网络，它告诉我们图像中每个像素的亮度值），因此计算机视觉问题就是根据这个像素点亮度矩阵来告诉我们这些数值代表一个汽车门把手（或其他部位）。

![image-20210925112227613](E:\md笔记\PyTorch\images\image-20210925112227613.png)

现在，我们有汽车图像和一些非汽车图像，我们从这些图片中选择一组像素点位，我们选择了像素点1和像素点2，位置如下图：

![image-20210925112426257](E:\md笔记\PyTorch\images\image-20210925112426257.png)

在坐标系中，我们根据像素点1和像素点2的强度来标出这张图片所处的位置。最终坐标系如下图所示（$+$表示汽车，$-$表示非汽车）：

![image-20210925132033159](E:\md笔记\PyTorch\images\image-20210925132033159.png)

假使我们采用的都是50x50像素的小型灰度图片，那么将所有的像素视为特征，则会有 2500个特征；如果我们采用的是RGB彩色图像，那么每个像素点还都包括红绿蓝三个值，那么会有7500个特征。因此，如果我们要通过包含所有的二次项特征来学习得到非线性假设，则会有约${{2500}^{2}}/2$个（接近3百万个）特征。**普通的逻辑回归模型，不能有效地处理这么多的特征，这时候我们需要神经网络。**

神经网络在学习复杂的**非线性假设**上被证明是一种非常好的算法。

## 8.2 神经元与大脑

本节，我们要讲述神经网络的一些背景知识，由此我们能知道可以用它来做什么。

神经网络的起源是人们想尝试设计出模仿大脑的算法，它的理念就是，如果我们想要建立学习系统，那为什么不去模仿我们所认识的最神奇的学习机器——人类的大脑呢？

神经网络逐渐兴起于二十世纪八九十年代，应用得非常广泛。但由于各种原因，在90年代的后期应用减少了。但是最近，神经网络又东山再起了。其中一个原因是：神经网络是计算量有些偏大的算法，与此同时近些年计算机的运行速度变快，足以真正运行起大规模的神经网络。正是由于这个原因，和其他一些我们后面会讨论到的技术因素，如今的神经网络对于许多应用来说是最先进的技术。

要想让神经网络能够模仿大脑，你似乎得写出各种各样的软件来对其进行各方面的模仿。我们能否假设大脑所做的所有事情并不需要成千上万个不同的程序来实现，而仅需要一个单一的学习算法？下面，我们将讲述一下这一假设可行的证据。

神经重接实验（此处略）

从某种意义上来说，如果我们能找出大脑的学习算法，然后在计算机上执行大脑学习算法或与之相似的算法，也许这将是我们向人工智能迈进做出的最好的尝试。

**神经网络是现代机器学习应用最有效、最先进的技术方法。**

## 8.3 模型表示（1）

我们如何表示神经网络？换句话说，在运用神经网络时，我们该如何表示我们的假设或模型。

神经网络模仿了大脑中的神经元，因此，为了解释如何表示假设模型，我们先来看单个神经元在大脑中是什么样的（如下图所示）：

- **细胞体（Cell body）**
- 输入通道——**树突（Dendrites）**，接收其他神经元传递来的信息。
- 输出通道——**轴突（Axon）**，给其他神经元传递信号或者传送消息。

![image-20210925130126412](E:\md笔记\PyTorch\images\image-20210925130126412.png)

神经元是一个计算单元，它从输入通道接受一定数目的信息，并做一些计算，然后将结果通过它的轴突传送到其他节点或者大脑中的其他神经元。神经网络是大量神经元相互链接并通过电脉冲来交流的一个网络。

![image-20210925130413154](E:\md笔记\PyTorch\images\image-20210925130413154.png)

上图是一组神经元的示意图。神经元利用微弱的电流进行沟通，这些弱电流也称作**动作电位**。如果你想活动一块肌肉，就会触发一个神经元给你的肌肉发送脉冲，并引起你的肌肉收缩；如果你的眼睛想要给大脑传递一个消息，那么它就像发送电脉冲给大脑。

如下图（以逻辑回归模型为例），在一个人工神经网络里，我们将一个神经元模拟成一个逻辑单元（**下图的黄色圆圈代表神经元**）：通过树突/输入通道传递给它一些信息，然后神经元做一些计算，通过输出通道/轴突输出计算结果。在这个例子中，神经元接收输入 $x_1$、$x_2$、$x_3$，计算 $h_{\theta}(x)=\frac{1}{1+e^{-e^Tx}}$ 后输出结果。

![image-20210925132049169](E:\md笔记\PyTorch\images\image-20210925132049169.png)

> 绘制神经网络时，通常不把$x_0$（$x_0=1$）绘制出来，除非有必要。这个$x_0$被称作**偏置单元（bias unit）**或**偏置神经元**。

有时我们会说“这是一个带有sigmoid/logistic激活函数的人工神经元”，在人工神经网络中，**激活函数**是指代非线性函数 $g(z)$ 的另一个术语，$g(z)=\frac{1}{1+e^{-z}}$.  另外，在神经网络中，模型的参数 $\theta$ 被称为**权重**。

-- --

## 8.4 正向传播

设计下图所示的神经网络（$x_0$、$a_0$均为1）：

![image-20210925134629630](E:\md笔记\images\image-20210925134629630.png)

神经网络模型是许多逻辑单元按照不同层级组织起来的网络，每一层的输出变量都是下一层的输入变量。下图为一个3层的神经网络，第一层称为**输入层**（**Input Layer**），最后一层称为**输出层**（**Output Layer**），中间一层称为**隐藏层**（**Hidden Layers**）。

下面我们解释一下这个神经网络究竟做了些什么。

- $a_{i}^{\left( j \right)}$ ：第$j$ 层的第 $i$ 个神经元的**激活项/激活单元**（所谓激活项是指由前一个神经元计算并输出的值）。

- ${{\Theta }^{\left( j \right)}}$：从第 $j$ 层映射到第$ j+1$ 层时的权重的矩阵。

对于上图所示的模型，激活单元和输出分别表达为：

$a_{1}^{(2)}=g(\Theta_{10}^{(1)}{{x}_{0}}+\Theta_{11}^{(1)}{{x}_{1}}+\Theta_{12}^{(1)}{{x}_{2}}+\Theta_{13}^{(1)}{{x}_{3}})$ 

$a_{2}^{(2)}=g(\Theta_{20}^{(1)}{{x}_{0}}+\Theta_{21}^{(1)}{{x}_{1}}+\Theta_{22}^{(1)}{{x}_{2}}+\Theta_{23}^{(1)}{{x}_{3}})$ 

$a_{3}^{(2)}=g(\Theta_{30}^{(1)}{{x}_{0}}+\Theta_{31}^{(1)}{{x}_{1}}+\Theta_{32}^{(1)}{{x}_{2}}+\Theta_{33}^{(1)}{{x}_{3}})$ 

${{h}_{\Theta }}(x)=a_1^{(3)}=g(\Theta_{10}^{(2)}a_{0}^{(2)}+\Theta_{11}^{(2)}a_{1}^{(2)}+\Theta_{12}^{(2)}a_{2}^{(2)}+\Theta_{13}^{(2)}a_{3}^{(2)})$

> 解释：$a_{1}^{(2)}$表示第一个神经元的激活值等于sigmoid/logistic激活函数作用在 $\Theta_{10}^{(1)}{{x}_{0}}+\Theta_{11}^{(1)}{{x}_{1}}+\Theta_{12}^{(1)}{{x}_{2}}+\Theta_{13}^{(1)}{{x}_{3}}$ 线性组合上的结果。

可知，$\Theta_1$是一个3×4的矩阵。**更一般地，$\Theta_j$矩阵以第 $j+1$层的激活单元数量为行数，以第 $j$ 层的激活单元数加一为列数的矩阵。**

以上，我们计算出了三个隐藏单元的激活值和假设函数，这一过程就是**前向传播（forward propagation）**。

将上面的计算过程用向量进行表示：

![image-20210925144049956](E:\md笔记\images\image-20210925144049956.png)

我们令 ${{z}^{\left( 2 \right)}}={{\Theta }^{\left( 1 \right)}}x$，则 ${{a}^{\left( 2 \right)}}=g({{z}^{\left( 2 \right)}})=g({\Theta}^{(1)}x)$ ：

![image-20210925144825165](E:\md笔记\images\image-20210925144825165.png)

计算后添加 $a_{0}^{\left( 2 \right)}=1$， 令${{z}^{\left( 3 \right)}}={{\theta }^{\left( 2 \right)}}{{a}^{\left( 2 \right)}}$，则 $h_\theta(x)={{a}^{\left( 3 \right)}}=g({{z}^{\left( 3 \right)}})$：

![image-20210925145213115](E:\md笔记\images\image-20210925145213115.png)

## 8.5 模型表示（2）

> 为什么这样是表示神经网络的好方法？神经网络如何学习复杂的非线性假设函数？

进一步对上一节中的神经网络进行解释。我们先把左半部分遮住：

![image-20210925145837726](E:\md笔记\images\image-20210925145837726.png)

则上图其实就表示以$a_0, a_1, a_2, a_3$作为输入，按照**Logistic Regression**的方式输出$h_\theta(x)$：

![image-20210925145949631](E:\md笔记\images\image-20210925145949631.png)

其实神经网络就像是 **logistic regression**，只不过我们把 **logistic regression** 中的输入向量$\left[ x_1\sim {x_3} \right]$ 变成了中间层的$\left[ a_1^{(2)}\sim a_3^{(2)} \right]$, 即: $h_\theta(x)=g\left( \Theta_0^{\left( 2 \right)}a_0^{\left( 2 \right)}+\Theta_1^{\left( 2 \right)}a_1^{\left( 2 \right)}+\Theta_{2}^{\left( 2 \right)}a_{2}^{\left( 2 \right)}+\Theta_{3}^{\left( 2 \right)}a_{3}^{\left( 2 \right)} \right)$ 。

我们可以把 $a_0, a_1, a_2, a_3$ 看成更为高级的特征值，也就是 $x_0, x_1, x_2, x_3$ 的进化体，并且它们是由 $x$ 与 $\theta$ 决定的，因为是梯度下降的，所以 $a$ 是变化的，并且变得越来越厉害，所以这些更高级的特征值远比初始输入 $x_0, x_1, x_2, x_3$ 厉害。 这就是神经网络相比于逻辑回归和线性回归的优势。这样，神经网络就可以利用隐藏层计算更复杂的特征，并输入到最后的输出层；也可以学习更复杂的假设函数。

## 8.6 例子与直观理解

从本质上讲，神经网络能够通过学习得出其自身的一系列特征。在普通的逻辑回归中，我们被限制只能使用数据的原始特征 $x_1,x_2,...,{{x}_{n}}$。在神经网络中，原始特征只是输入层，在我们上面三层的神经网络例子中，第三层也就是输出层做出的预测利用的是第二层的特征，而非输入层中的原始特征，我们可以认为第二层中的特征是神经网络通过学习后自己得出的一系列用于预测输的新特征。

神经网络中，单层神经元（无中间层）的计算可用来表示逻辑运算，比如逻辑与(**AND**)、逻辑或(**OR**)。

### 逻辑与(**AND**)

我们可以用这样的一个神经网络表示 **AND** 函数：

<img src="E:\md笔记\images\image-20210925191024701.png" alt="image-20210925191024701" style="zoom: 67%;" />

根据上图信息，得出输出函数$h_\theta(x)$即为：$h_\Theta(x)=g\left( -30+20x_1+20x_2 \right)$

下面对这个输出函数进行验算：

> 注意，$g(-4.6)≈0.01$，$g(4.6)≈0.99$. 

![image-20210925184508379](E:\md笔记\images\image-20210925184508379.png)

![image-20210925184520363](E:\md笔记\images\image-20210925184520363.png)

所以我们有：$h_\Theta(x) \approx {x}_1 \text{AND} {x}_2$

### 逻辑或(OR)

如下图，逻辑或的假设函数可以表示为$h_\Theta(x)=g\left( -10+20x_1+20x_2 \right)$. 

![image-20210925184550946](E:\md笔记\PyTorch\images\image-20210925184550946.png)

### 逻辑非(NOT)

如下图，逻辑非的假设函数可以表示为$h_\Theta(x)=g( 10-20x_1)$.

> 令$x_1$的权重是一个较大的负数。

![image-20210925191936104](E:\md笔记\PyTorch\images\image-20210925191936104.png)

### 同或(XNOR)

同或的目标函数 ：$y=NOT (x_1 XOR x_2)$ 或 $x_1 XNOR x_2$

> 异或的目标函数 ：$y=x_1 XOR x_2$

同或情况的图像可以表示成下图左侧，右侧是一个类似于同或问题的数据集的分类问题。显然，我们需要一个非线性的决策边界来分开正样本和负样本。

![image-20210925185928125](E:\md笔记\images\image-20210925185928125.png)

我们要把$x_1 AND x_2$、$(NOT x_1)AND(NOTx_2)$、$x_1ORx_2$结合起来计算XNOR运算。

<img src="E:\md笔记\images\image-20210925195837273.png" alt="image-20210925195837273" style="zoom:80%;" />

对上面XNOR神经网络的更通俗的解释：我们的输入都放在**输入层**，然后在中间放一个**隐藏层**用来计算一些关于输入的略微复杂的功能，然后再继续增加一层用于计算一个更复杂非线性函数。当网络拥有许多层，在第二层有一些关于输入的相对简单的函数，第三层又在此基础上计算更加复杂的方程，以此类推，以后的每一层都将计算越来越复杂的函数。

## 8.7 多元分类

如何使用神经网络解决多类别分类问题？

如果我们要训练一个神经网络算法来识别路人、汽车、摩托车和卡车，在输出层我们应该有4个值。首先建立一个有四个输出单元的神经网络（假设从上到下依次表示判断是否是行人、汽车、摩托车、卡车）。下图构建了一个可能的神经网络：

![image-20210925212450068](E:\md笔记\images\image-20210925212450068.png)

# 9 神经网络（深入）

> 本章将学习：如何构建我们的训练集，以及如何让神经网络自动学习权重/参数；讲解一个能在给定训练集下为神经网络拟合参数的学习算法【和大多数学习算法一样，我们将从拟合神经网络参数的代价函数开始讲起】。

## 9.1 代价函数

假设神经网络的训练样本有 $m$ 个，每个训练样本包含一个输入 $x$ 和一个输出 $y$ ；$L$表示神经网络层数；$S_l$表示$l$层的神经单元个数(不算偏置单元)，下图中 $S_1=3, S_2=S_3=5, S_4=S_L=4$。

![image-20210926094846579](E:\md笔记\images\image-20210926094846579.png)

将神经网络的分类定义为两种情况（上图下半部分）：

- 二元分类：输出 $y=0  or  1$；仅有一个输出单元（即$S_L=1$）;$h_{\Theta}(x)$会是一个实数。

- 多类别分类：有$K(K>2)$个输出单元（即$S_L=K$）;$h_{\Theta}(x)$会是一个$K$维向量，其中元素为1即对应$x$所属的类别。

-- --

我们回顾逻辑回归问题中使用的代价函数：

$ J\left(\theta \right)=-\frac{1}{m}\left[\sum_\limits{i=1}^{m}{y}^{(i)}\log{h_\theta({x}^{(i)})}+\left(1-{y}^{(i)}\right)log\left(1-h_\theta\left({x}^{(i)}\right)\right)\right]+\frac{\lambda}{2m}\sum_\limits{j=1}^{n}{\theta_j}^{2} $

在逻辑回归中，我们只有一个标量型的输出变量，也只有一个因变量 $y$。但是在神经网络中，我们可以有很多输出变量，即我们的 $h_\theta(x)$ 是一个 $K$ 维向量：$$h_\Theta\left(x\right)\in \mathbb{R}^{K}$$. 

> 当神经网络处理的是二类分类时，这里 $K=1$. 

训练集中的因变量 $y$ 也是一个 $K$ 维向量。因此==神经网络的代价函数==会比逻辑回归更加复杂一些：$\newcommand{\subk}[1]{ #1_k }$  

$J(\Theta) = -\frac{1}{m} \left[ \sum\limits_{i=1}^{m} \sum\limits_{k=1}^{k} {y_k}^{(i)} \log \subk{(h_\Theta(x^{(i)}))} + \left( 1 - y_k^{(i)} \right) \log \left( 1- \subk{\left( h_\Theta \left( x^{(i)} \right) \right)} \right) \right] + \frac{\lambda}{2m} \sum\limits_{l=1}^{L-1} \sum\limits_{i=1}^{s_l} \sum\limits_{j=1}^{s_{l+1}} \left( \Theta_{ji}^{(l)} \right)^2$

> $${\left({h_\Theta}\left(x\right)\right)}_{i}$$ 表示选择神经网络的输出向量中的第$i$个元素。

- 对于神经网络来说，不再只有一个逻辑回归输出单元，取而代之的是$K$个。假设神经网络的最后一层有4个输出单元，那么这个求和项 $\sum\limits_{i=1}^{m} \sum\limits_{k=1}^{k} {y_k}^{(i)} \log \subk{(h_\Theta(x^{(i)}))}$ 就表示求$K$从1到4的每一个逻辑回归算法的代价函数，然后按四次输出的顺序依次把这些代价函数加起来。这个求和符号应用于 $y_k$ 和 $h_k$ 是因为我们主要是将第$K$个输出单元的值和 $y_k$ 的值的大小作比较。$y_k$的值就是这些向量中表示其应属于哪个类的量，例如，$y_k=[0,0,1,0]^{T}$。

- 正则化项仍然需要除去对应于偏差值的项，即排除了每一层 $\theta_0$ 后每一层的 $\theta$ 矩阵的和。最里层的循环 $j$ 循环所有的行（由$s_{l+1}$ 层的激活单元数决定），循环 $i$ 则循环所有的列，由该层（$s_l$层）的激活单元数所决定。

## 9.2 反向传播

> - 之前，我们在计算神经网络预测结果的时候采用了**正向传播方法**——从第一层开始正向一层一层进行计算，直到最后一层求得 $h_{\theta}\left(x\right)$。
>
> - 现在，为了计算代价函数的偏导数$\frac{\partial}{\partial\Theta^{(l)}_{ij}}J\left(\Theta\right)$，我们需要采用一种反向传播算法——首先计算最后一层的误差，然后再一层一层反向求出各层的误差，直到倒数第二层。 

如下图：

![image-20210926132715072](E:\md笔记\images\image-20210926132715072.png)

假设我们的训练集只有一个训练样本$\left({x},{y}\right)$。首先应用前向传播算法预测结果：

![image-20210926133144907](E:\md笔记\images\image-20210926133144907.png)

> 解释：$a^{(1)}$是第一层的激活值，它们是初始输入 $x$；然后我们计算$z^{{(2)}}$, $a^{(2)}$( $g$ 是一个Sigmoid激活函数)【第一个隐藏层的激活值，即神经网络的第二层】；继续两次前向传播，计算得到$a^{(3)}$、$a^{(4)}$【即$h(x)$的输出】。

下面使用反向传播算法计算偏导数。反向传播算法从直观上说就是==对每一个结点计算这样一项 ${\delta}_j^{(l)}$==，它表示第 $l$ 层的第 $j$ 个结点的误差。我们还记得 $a_j^{(l)}$ 表示的是第 $l$ 层第 $j$ 个结点的激活值，所以这个 ${\delta}$ 项在某种程度上就捕捉到了我们在这个神经节点的激活值的误差。我们从最后一层的误差开始计算，则：

$\delta^{(4)}=a^{(4)}-y$ 

> 这里 ${\delta}$ ，$a$ ，$y$ 都是维数为输出单元数目的向量。

我们利用这个误差值来计算前一层的误差：

$\delta^{(3)}=\left({\Theta^{(3)}}\right)^{T}\delta^{(4)}.* g'\left(z^{(3)}\right)$ 

其中， $g'(z^{(3)})$是 $S$ 形函数的导数，$g'(z^{(3)})=a^{(3)}\ast(1-a^{(3)})$；而$(θ^{(3)})^{T}\delta^{(4)}$ 则是权重导致的误差的和。

下一步是继续计算第二层的误差：

 $ \delta^{(2)}=(\Theta^{(2)})^{T}\delta^{(3)}.*g'(z^{(2)})$ 

因为第一层是输入变量，不存在误差，所以计算到此为止。

我们有了所有的误差的表达式后，便可以计算代价函数的偏导数了，假设 $λ=0$，即我们不做任何正则化处理，==则有：$\frac{\partial}{\partial\Theta_{ij}^{(l)}}J(\Theta)=a_{j}^{(l)} \delta_{i}^{l+1}$==. 

> $l$ 代表目前所计算的是第几层；$j$ 代表目前计算层中的激活单元的下标，也将是下一层的第$j$个输入变量的下标；$i$ 代表下一层中误差单元的下标，是受到权重矩阵中第$i$行影响的下一层中的误差单元的下标。

总之，以上，我们通过计算这些 ${\delta}$ 项，可以非常快速地计算出所有参数的偏导数项。

-- --

下面，我们再次对反向传播算法进行解释。当我们有一个非常大的训练样本时，而不是上面例子假设的只有一个训练样本，我们是这样做的：

![image-20210927163352699](E:\md笔记\images\image-20210927163352699.png)

假设有$m$个训练样本，用$\Delta^{(l)}_{ij}$来表示误差矩阵，它将被用来计算偏导项 $\frac{\partial}{\partial\Theta_{ij}^{(l)}}J(\Theta)$ .  接下来，遍历训练集：

对于第 $i$ 个循环而言，我们将取训练样本 $(x(i), y(i))$ ；然后要设定 $a^{(1)}$(即输入层的激活函数)为 $x^{(i)}$；接下来我们运用正向传播来计算第二层的激活值，然后是第三层，第四层......

接下来，我们将用我们这个样本的输出值 $y^{(i)}$ 来计算对应的误差 ${\delta}^{(L)}=a^{(L)}-y^{(i)}$. 

然后，运用反向传播算法，来计算 ${\delta}^{(L-1)}$、${\delta}^{(L-2)}$、...、${\delta}^{(2)}$；不需要计算 ${\delta}^{(1)}$ 是因为我们不需要对输入层考虑误差项，输入层就是按照给定的训练集进行输入的，不存在误差。

最后，我们将用这些大写的${\Delta}_{ij}^{(l)}:={\Delta}_{ij}^{(l)}+a_j^{(l)}{\delta}_i^{(l+1)}$ 来累积我们的偏导数项。【观察此式，我们其实可以将它写成向量的形式，具体地说，如果你把 ${\delta}_{ij}$ 看作一个矩阵，$i$, $j$ 代表矩阵中的位置，那么如果 ${\delta}^{(l)}$ 是一个矩阵，我们就可以写成 ${\Delta}^{(l)}:={\Delta}^{(l)}+{\delta}^{(l+1)}(a^{(l)})^T$ .】

执行这个for循环之后，再利用上图中最下面的两个式子计算 $D_{ij}^{(l)}$ .【$D_{ij}^{(l)}$ 就刚好是代价函数对于每个参数的偏导数==（“这个严格的证明对你来说可能太复杂”）==，然后就可以使用梯度下降或者另一种高级优化算法。】

以上，就介绍完了反向传播算法，以及如何计算出网络中所有代价函数的偏导数，这其中包含了很多细节和大量的步骤，在编程作业之后和视频之后，我们会给你一些总结，将这些算法都联系起来，让你明白自己应该实现什么，比如实现反向传播、计算神经网络中的代价函数关于参数的偏导数。

-- --

## 9.3 矩阵 <--> 向量

怎样把你的参数从矩阵展开成向量，以便我们在高级最优化步骤中使用？

首先执行代价函数，输入参数是${\theta}$ ，函数返回代价值以及导数值；然后你可以将返回值传递给一个高级最优化算法`fminunc`：

```matlab
function [jVal, gradient] = costFunction(theta)
...
optTheta = fminunc(@costFunction, initialTheta, options)
```

在神经网络中，下面这些值都是矩阵的形式(假设神经网络的层数$L=4$)：

${\Theta^{(1)}}$、${\Theta^{(2)}}$、${\Theta^{(3)}}$ ; $D^{(1)}$、$D^{(2)}$、$D^{(3)}$. 

所以我们将讲述如何将它们变成向量，然后才能在上面那段代码中使用（因为在上面那段代码中，变量 `theta`、`initialTheta` 都是 `n+1` 维的向量）。

> 正向传播和反向传播时使用矩阵；使用一些高级优化算法时，通常要求这些优化函数的参数为一个长向量。

假如我们有下面这样的一个神经网络：

![image-20210928094213635](E:\md笔记\PyTorch\images\image-20210928094213635.png)

在**Octave**中，将矩阵转化为向量：

```octave
thetaVec = [ Theta1(:); Theta2(:); Theta3(:) ]; % 将Theta1，Theta2，Theta3中的元素全部展开，成为一个很长的向量thetaVec
Dvec = [D1(:); D2(:); D3(:)]; % 将D1，D2，D3中的元素全部展开，成为一个很长的向量Dvec
```

将向量转化为矩阵：

```octave
Theta1 = reshape(thetaVec(1:110), 10, 11);
Theta2 = reshape(thetaVec(111:220), 10, 11);
Theta3 = reshape(thetaVec(221:231), 1, 11);
```

为了使这一过程更具体，下面我们来看怎样将这一方法应用于我们的学习算法。有以下初始值：${\Theta^{(1)}}$、${\Theta^{(2)}}$、${\Theta^{(3)}}$, 将其展开成向量，以执行`fminunc`；然后执行代价函数（传入的参数为`thetaVec`），再重新得到矩阵形式的${\Theta^{(1)}}$、${\Theta^{(2)}}$、${\Theta^{(3)}}$，从而执行正向传播和反向传播算法得到导数$D^{(1)}$、$D^{(2)}$、$D^{(3)}$和代价函数$J({\theta})$；最后，展开$D^{(1)}$、$D^{(2)}$、$D^{(3)}$为向量，从而计算得到向量`gradientVec`，这个值由代价函数`costFunction` 返回。以上过程均是对下图的解释：

![image-20210928100334150](E:\md笔记\PyTorch\images\image-20210928100334150.png)

## 9.4 梯度检测

反向传播算法含有很多细节，因此实现起来比较困难，并且它有一个不好的特性：很容易产生一些微妙的漏洞；当它与梯度下降或者其他算法一同工作时，看起来它能正常运行，并且代价函数$J({\theta})$ 在每次梯度下降的迭代中也在不断减小，但是到了最后会发现结果并不理想。

为了避免这样的问题，我们采取一种叫做梯度的数值检验（**Numerical Gradient Checking**）方法（就是高数上的**导数的定义**）。这种方法的思想是通过估计梯度值来检验我们计算的导数值是否几乎正确。

对梯度的估计采用的方法是在代价函数上沿着切线的方向选择离两个非常近的点，然后计算两个点的平均值用以估计梯度。即对于某个特定的 $\theta$，我们计算出在 $\theta$-$\varepsilon $ 处和 $\theta$+$\varepsilon $ 的代价值（$\varepsilon $是一个非常小的值，通常选取 0.0001），然后求两个代价的平均，用以估计在 $\theta$ 处的代价值：

![image-20210928102143968](E:\md笔记\PyTorch\images\image-20210928102143968.png)

**Octave** 中代码如下：

```octave
gradApprox = (J(theta + EPSILON) – J(theta - EPSILON)) / (2*EPSILON)
```

上面我们仅考虑了 ${\theta}$ 是实数的情况，考虑更普遍的情况—— $\theta$ 是一个 `n` 维向量 ${\theta} = [{\theta}_1, {\theta}_2, ..., {\theta}_n]$。 ${\theta}$ 可能是 ${\Theta^{(1)}}$、${\Theta^{(2)}}$、${\Theta^{(3)}}$的展开。我们用上面计算导数的思想来计算所有偏导数：

![image-20210928102919107](E:\md笔记\PyTorch\images\image-20210928102919107.png)

这些等式让你能够**从数值上来估算代价函数 $J$关于任何参数的偏导数**。具体来说，我们就是要计算以下这些东西：

![image-20210928105109626](E:\md笔记\PyTorch\images\image-20210928105109626.png)

然后，我们将其与反向传播中得到的梯度 `DVec` 进行比较：

![image-20210928105121580](E:\md笔记\PyTorch\images\image-20210928105121580.png)

如果两者相等或者非常相近，那么我们就可以确定反向传播的实现是正确的。

-- --

总结——如何实现数值上的梯度检验：

1. 通过反向传播来计算 `DVec`

2. 实现数值上的梯度检验，计算出 `gradApprox`

3. 确保 `DVec` 与 `gradApprox` 非常相近

4. 关闭梯度检验（不用再计算 `gradApprox` 了），开始利用反向传播（计算 `DVec` ）训练网络

   > 因为计算的 `gradApprox` 的运算量很大，运行速度会很慢；但**反向传播计算 `DVec` 的过程是一个高性能的计算导数的方法**。

## 9.5 随机初始化

当执行一个算法时，通常需要对 ${\theta}$ 初始化，例如梯度下降法或者高级优化算法：

![image-20210928110802325](E:\md笔记\PyTorch\images\image-20210928110802325.png)

将所有参数初始化0不会起到任何作用。如果我们令下面这个神经网络的所有参数都初始化为0，即下面六条线对应的权重均为0，那么第二层所有激活单元的值都将相同；同理，如果我们初始所有的参数都为一个非0的数，结果也是一样的。这意味着，所有的隐藏单元都在计算相同的特征，所有的隐藏单元都以相同的函数作为输入，这是一种高度冗余的现象，最后的逻辑回归单元只能得到一个特征，因为所有的单元都一样，这种情况阻止了神经网络去学习多样而有趣的东西。这一问题被称作**对称权重问题**。

![image-20210928111819251](E:\md笔记\PyTorch\images\image-20210928111819251.png)

为了解决这个问题，应对参数随机初始化。我们通常初始化 **参数/权重/${\theta}$** 为 $(-ε, ε)$ （ε很小）范围的一个随机值。假设我们要随机初始一个尺寸为10×11的参数矩阵，代码如下：

```octave
Theta1 = rand(10, 11) * (2*INIT_EPSILON) - INIT_EPSILON;
```

> `rand`函数产生0-1之间的随机数，所以`rand(10, 11) * (2*INIT_EPSILON)`的范围在$(0, 2ε)$ ，最后 `Theta1` 的范围就在$(-ε, ε)$ 。

## 9.6 总结

在训练一个神经网络时，我们要做的第一件事是**选择一种网络架构**，即**确定神经元之间的连接模式**（如神经网络的层数、每一层有多少个神经元）。有以下规则：

- 输入层的单元数目 = 训练集的特征数量
- 输出层的单元数目 = 分类问题中的类别数
- 隐藏层的单元数目 = 一个合理的默认设置是将其设为1；如果希望隐藏层数目 > 1, 则通常令每个隐藏层所含有的隐藏单元数目是一样的【通常情况下，隐藏单元的数目越多越好，但同时计算量会变大】；每个隐藏层所包含的隐藏单元数量应该与训练集的特征数目相匹配——隐藏单元的数目应该和输入特征的数量相同或者是它的二/三/四倍。

**训练一个神经网络的步骤：**

1. 随机初始化权重

2. 前向传播（计算 $h_{(\Theta)}(x^{(i)})$）

3. 计算代价函数 $J({\Theta})$

4. 反向传播（计算偏导数）$\frac{\partial}{\partial\Theta_{ij}^{(l)}}J(\Theta)$【具体可看下图】

   ![image-20210928130155013](E:\md笔记\images\image-20210928130155013.png)

5. 梯度检查——将反向传播得到的导数与数值计算得到的导数进行比较

6. 停止梯度检查，使用梯度下降或其他高级优化算法（如LBFGS算法、共轭梯度法等）以及反向传播算法来最小化$J({\theta})$ 【注意：对于神经网络，代价函数 $J({\theta})$ 是一个非凸函数，因此理论上可能停留在局部最小值的位置，但通常这不是大问题】

   > 梯度下降算法的原理是，我们从某个随机的初始点开始，它将会不停地往下下降，其中，反向传播的目的是算出梯度下降的方向，而梯度下降的作用是沿着这个方向一点点的不断下降，一直到(局部)最优点。
   >
   > ![image-20210928134733463](E:\md笔记\images\image-20210928134733463.png)



