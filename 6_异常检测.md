# 15 异常检测

## 15.1 简介

什么是异常检测呢？

给定数据集 { ${ x^{(1)},x^{(2)},..,x^{(m)}}$ }，且数据集中的数据都是正常的，我们希望知道新的数据 $x_{test}$ 是不是异常的。我们所构建的模型要能根据该测试数据的位置判断出其属于一组数据的可能性 $p(x_{test})$。

- $p(x_{test})$ < $\epsilon$ ---> 标记为异常(anomaly)

- $p(x_{test})$ > $\epsilon$ ---> 标记为正常(ok)

例如：

![image-20211006184844842](E:\md笔记\PyTorch\images\image-20211006184844842.png)

异常检测的应用：

1. 识别欺骗。例如在线采集而来的有关用户的数据，一个特征向量中可能会包含如：用户多久登录一次，访问过的页面，在论坛发布的帖子数量，甚至是打字速度等。尝试根据这些特征构建一个模型，可以用这个模型来识别那些不符合该模式的用户。

2. 工业生产领域。一个数据中心里的一台计算机的特征可能包含：内存使用情况，被访问的磁盘数量，**CPU**的负载，网络的通信量等。根据这些特征可以构建一个模型，用来判断某些计算机是不是有可能出错了。

## 15.2 高斯分布

> 高斯分布也称正态分布。

通常如果我们认为若变量 $x$ 符合高斯分布 $x \sim N(\mu, \sigma^2)$ ，则其**概率密度函数**为： $p(x;\mu,\sigma^2)=\frac{1}{\sqrt{2\pi}\sigma}\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)$。其中，均值 $μ$ 和方差 $σ^2$ 的计算方法如下： 

$\mu=\frac{1}{m}\sum\limits_{i=1}^{m}x^{(i)}$ 

$\sigma^2=\frac{1}{m}\sum\limits_{i=1}^{m}(x^{(i)}-\mu)^2$

> $\sigma$ 被称为标准差。高斯分布的性质：积分为1（曲线下的面积为1）。

高斯分布样例：

![image-20211006191518277](E:\md笔记\images\image-20211006191518277.png)

> - $\sigma$ 控制曲线的宽度，与此同时，又面积固定为1，所以越宽，则越矮；越窄，则越高。
>
> - 某一处聚集的数据越多，对应的高斯分布曲线就越高：
>
>   ![image-20211006204216901](E:\md笔记\images\image-20211006204216901.png)
>
> - 机器学习中，对于方差我们通常只除以 $m$ 而非统计学中的 $(m-1)$。这里顺便提一下，在实际使用中，到底是选择使用 $\frac{1}{m}$ 还是 $\frac{1}{(m-1)}$ 其实区别很小，只要你有一个还算大的训练集。在机器学习领域大部分人更习惯使用 $\frac{1}{m}$ 这个版本的公式。这两个版本的公式在理论特性和数学特性上稍有不同，但是在实际使用中，他们的区别甚小，几乎可以忽略不计。

## 15.3 构建异常检测算法

> 本节将应用高斯分布开发异常检测算法。

**【异常检测算法】**

0. 有训练集 { $x^{(1)},x^{(2)},...,x^{(m)}$ }，

1. 针对每一个训练样本的特征计算出对应的 $\mu$ 和 $\sigma^2$ 的估计值：

   $\mu_j=\frac{1}{m}\sum\limits_{i=1}^{m}x_j^{(i)}$ 【特征量 j 的平均值】

   $\sigma^2=\frac{1}{m}\sum\limits_{i=1}^{m}(x^{(i)}-\mu)^2$

2. 计算 $p(x)$：

   $p(x)=\prod\limits_{j=1}^np(x_j;\mu_j,\sigma_j^2)=\prod\limits_{j=1}^1\frac{1}{\sqrt{2\pi}\sigma_j}exp(-\frac{(x_j-\mu_j)^2}{2\sigma_j^2})$

3. 判断。当 $p(x) < \varepsilon$ 时，为异常。

**【实例】**

下图是一个有两个特征的训练集：

![image-20211006213349143](E:\md笔记\PyTorch\images\image-20211006213349143.png)

计算得到这两个特征的均值和方差：

![image-20211006213541781](E:\md笔记\PyTorch\images\image-20211006213541781.png)

计算得到 $p(x)$ ：

![image-20211006213629547](E:\md笔记\PyTorch\images\image-20211006213629547.png)

假定有两个新数据，如下图绿色标记所示。那么如何判断它们是正常还是异常呢？我们可以令 $\epsilon = 0.02$，然后分别计算出 $p(x_{test}^{(1)}),p(x_{test}^{(2)})$ ：

![image-20211006214140353](E:\md笔记\PyTorch\images\image-20211006214140353.png)

与 $\epsilon$ 比较后即可得出结果。

> - 如果是看图像直接粗略的判断是否为异常值，则可以看 $x_1, x_2$ 组成的二维坐标，也可以看 $p(x)$ 的图像。如下图，这两幅图里的粉色区域内的数据都更有可能被判断为异常值。
>
> <img src="E:\md笔记\PyTorch\images\image-20211006214432308.png" alt="image-20211006214432308" style="zoom:67%;" />

## 15.4 开发和评估异常检测系统

异常检测算法是一个非监督学习算法，意味着我们无法根据结果变量 $ y$ 的值来告诉我们数据是否真的是异常的。我们需要另一种方法来帮助检验算法是否有效。当我们开发一个异常检测系统时，我们从带标记（异常或正常）的数据着手，我们从其中选择一部分正常数据用于构建训练集(即使混有一点不正常数据也没关系)，然后用剩下的正常数据和异常数据混合的数据构成交叉检验集和测试集。

例如：我们有10000台正常 $(y=0)$ 引擎的数据，有20台异常 $(y=1)$ 引擎的数据。 这样分配数据：

> 上面的10020个数据都可以看作是**有标签的**数据，就是已经知道这些数据对应的是正常还是异常了。

- 6000台正常引擎的数据作为训练集

- 2000台正常引擎和10台异常引擎的数据作为交叉检验集

- 2000台正常引擎和10台异常引擎的数据作为测试集

具体的评价方法如下：

1. 使用**训练集**拟合模型 $p(x)$。

2. 在**交叉检验集**上，我们尝试使用不同的 $\varepsilon$ 值作为阀值，并预测数据是否异常，与真实结果比较。最后根据$F1$值来选择  $\varepsilon$。

   > 之所以要根据 $F_1$ 值来进行判断，是因为这里正常和异常的数据的比例差很多。

3. 选出 $\varepsilon$ 后，针对**测试集**进行预测，与真实值进行比较，计算模型的 $F1$值，得到模型最后的评估。

## 15.5 异常检测 VS 监督学习

上面，我们把数据看成是带标签(“正常”或“异常”)的了，这就和监督学习有点类似了。那么什么时候用异常检测算法，什么时候要监督学习呢？区别在哪里？

|      | 异常检测                                                     | 监督学习                                                     |
| ---- | :----------------------------------------------------------- | ------------------------------------------------------------ |
| 标签 | 非常少量的正向类, 大量的负向类                               | 同时有大量的正向类和负向类                                   |
| 选择 | 对于异常检测应用来说，经常有许多不同种类的异常，这样就很难从**小数量**的正样本中去学习异常，尤其是未来可能出现的异常(因为它可能**与已有的异常截然不同**)。此情况就更适合用高斯分布模型 $p(x)$ 来建模，而不是费尽心思对正样本建模 | 有足够多的正向类实例，用它们便可以训练出学习算法；且未来遇到的正向类实例与训练集中的将**非常近似** |
| 实例 | 欺诈行为检测、机器生产（例如飞机引擎）、检测数据中心的计算机运行状况 | 邮件过滤器、天气预报、肿瘤分类                               |

> 上表中的正向类表示异常数据，被标记为 $y=1$。

## 15.6 如何选择特征

对于异常检测算法，我们使用的特征是至关重要的，下面谈谈如何选择特征。

-- --

**【用直方图表示数据】**

用直方图将数据表示出来，就可以直观的看出这些数据是否符合高斯分布。不过，即使不接近高斯分布图，我们**使用高斯分布对特征建模得到 $p(x)$** 后，这个 $p(x)$ 也能很好的工作，但是最好还是将数据转换成高斯分布。比如下图中第一幅图接近高斯分布，但第二幅图不接近。

<img src="E:\md笔记\PyTorch\images\image-20211007145633101.png" alt="image-20211007145633101" style="zoom:50%;" />

> Octave 中画直方图用的是`hist()`。

下面讲解如何将数据转换成近似于高斯分布的样子：

- 方法一：对数据进行一次对数转换，即令 $x= log(x+c)$，其中 $c$ 为非负常数；
- 方法二：令 $x=x^c$，$c$ 为 0-1 之间的一个分数。

![image-20211007151646711](E:\md笔记\PyTorch\images\image-20211007151646711.png)

-- --

如何得到异常检测算法的特征？

与之前讨论监督学习算法时的**误差分析**步骤类似，我们先完整的训练出一个算法，然后在一组交叉验证集上运行算法，然后找出那些预测出错的样本，通过对这些样本的观察而找出其他可能的特征，从而优化学习算法。

【实例】

我们希望 $p(x)$ 在正常样本的情况下比较大，在异常样本的情况下比较小。一个很常见的问题是，当样本正常和异常时， $p(x)$ 的值都比较大。

假设下图为我们的无标签数据，只有一个特征 $x_1$，用高斯分布拟合的图像如下图。

<img src="E:\md笔记\PyTorch\images\image-20211007160445998.png" alt="image-20211007160445998" style="zoom:67%;" />

现在有一个异常样本 $x=2.5$ (上图中绿色标记所示)被错误的预测为正常。那么我们单独把它拿出来进行分析后，得到的结论是我们应该添加一个特征 $x_2$。然后我们在这种情况下对特征重新建模得到的图像：

<img src="E:\md笔记\PyTorch\images\image-20211007160512604.png" alt="image-20211007160512604" style="zoom:67%;" />

越向外，异常的情况就越大。上图异常样本已经比较偏外了，所以我们会预测它为异常。可见，添加特征 $x_2$ 后，模型更准确了。

以上，就是误差分析的过程。

> 我们通常可以通过将一些**相关的特征进行组合**，来获得一些新的更好的特征变量（这个特征变量可以使得异常数据的该特征值异常地大或小）。例如，在检测数据中心的计算机状况的例子中，我们可以用**CPU**负载与网络通信量的比例作为一个新的特征，如果该值异常地大，便有可能意味着该服务器是陷入了一些问题中。

## 15.7 多元高斯分布

> 多元高斯分布可以捕捉到之前的算法检测不出来的异常。

假使我们有两个相关的特征 $x_1, x_2$，而且这两个特征的值域范围比较宽，这种情况下，一般的高斯分布模型可能不能很好地识别异常数据。其原因在于，一般的高斯分布模型尝试的是去同时抓住两个特征的偏差，因此创造出一个比较大的判定边界。

<img src="E:\md笔记\PyTorch\images\image-20211007163534118.png" alt="image-20211007163534118" style="zoom: 50%;" />

下图是这两个相关特征。洋红色的线（根据 ε 的不同其范围可大可小）是一般的高斯分布模型获得的判定边界，很明显绿色的 **X** 所代表的数据点很可能是异常值，但是其 $p(x)$ 值却仍然在正常范围内。这就引起了错误。

![image-20211007163445318](E:\md笔记\PyTorch\images\image-20211007163445318.png)

多元高斯分布将创建上图中蓝色曲线所示的判定边界，从而能预测出绿色标记为异常点。

在一般的高斯分布模型中，我们计算 $p(x)$ 的方法是： 分别计算每个特征对应的几率，然后将其累乘起来。在多元高斯分布模型中，我们将构建特征的协方差矩阵，用所有的特征一起来计算 $p(x)$。

我们首先计算所有特征的平均值 $\mu$，然后再计算协方差矩阵 $\Sigma$： 

$\mu=\frac{1}{m}\sum_{i=1}^mx^{(i)}$

> $\mu $ 是一个向量，其每一个单元都是原特征矩阵中一行数据的均值。

$\Sigma = \frac{1}{m}\sum_{i=1}^m(x^{(i)}-\mu)(x^{(i)}-\mu)^T=\frac{1}{m}(X-\mu)^T(X-\mu)$

> $\Sigma$ 衡量的是方差，即 $x_1, x_2$ 的变化量。
>
> $|\Sigma|$ 是矩阵的行列式，在 **Octave** 中用 `det(sigma)`计算 ;
>
> $\Sigma^{-1}$ 是逆矩阵 .

最后我们计算多元高斯分布的 $p\left( x \right)$: 

$p(x)=\frac{1}{(2\pi)^{\frac{n}{2}}|\Sigma|^{\frac{1}{2}}}exp\left(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)\right)$ 其中：

-- --

下面我们来看看多元高斯分布的例子以及协方差矩阵 $\Sigma$ 是如何影响模型的：

> 对于多元高斯分布的图像来说（这里针对二元），图形下面鼓起来的部分的体积为1。

第一组：改变 $\Sigma$ 主对角线上的两个值，且保持这两个值相等。主对角线上的值分别是特征 $x_1, x_2$ 的方差，决定了在这个方向上的图像的宽度。【宽度宽了，又体积为1，则高度变矮】

![image-20211007202019648](E:\md笔记\PyTorch\images\image-20211007202019648.png)

第二组：改变 $\Sigma$ 主对角线上的其中一个的值。【呈椭圆形了】

![image-20211007202215581](E:\md笔记\PyTorch\images\image-20211007202215581.png)

第三组：改变 $\Sigma$ 副对角线上的两个值，且保持这两个值相等。副对角线上的值表示特征之间的相关性。如下第一幅图，副对角线上的值 0 --> 0.5 ---> 0.8，图像会变得更高、更窄，并且沿着 $x=y$ 这条线；$x,y$ 是一起增加的，这表明 $x, y$ 正相关。如下第一幅图，副对角线上的值 0 --> -0.5 ---> -0.8， $x, y$ 负相关。

![image-20211007202948569](E:\md笔记\PyTorch\images\image-20211007202948569.png)

![image-20211007203441195](E:\md笔记\PyTorch\images\image-20211007203441195.png)

$\mu$ 影响的是图像峰值所在的位置：

![image-20211007203636450](E:\md笔记\PyTorch\images\image-20211007203636450.png)

## 15.8 使用多元高斯分布的异常检测

如何开发一个异常监测系统？

首先用我们的训练集计算得到 $\mu,\Sigma$ 来拟合模型 $p(x)$ . 然后对测试样本计算 $p(x)$，计算结果大于 $\epsilon$，则表示该测试样本正常。 例如下图中的绿色标记将被预测为异常（实际也是异常）。

![image-20211007210645725](E:\md笔记\PyTorch\images\image-20211007210645725.png)

一般的高斯模型与多元高斯模型的关系？

![image-20211007211515037](E:\md笔记\PyTorch\images\image-20211007211515037.png)

原始模型是多元高斯模型的一种特殊情况。

什么情况下使用原始模型？什么情况下使用多元高斯模型？【原始模型被使用得更频繁】

| 原始模型                                                     | 多元高斯模型                                                 |
| :----------------------------------------------------------- | ------------------------------------------------------------ |
| 当原来的特征中有几个存在关联，那么我们可以构建一个新特征来表述这两个特征之间的关系，然后应用一般的高斯分布模型。 | 当原来的特征中有几个存在关联，我们不构造新特征，那么就直接使用多元高斯模型，因为它可以**自动捕捉到特征间的相关性**。 |
| 计算成本比较低 / 能适应巨大规模的n                           | 计算成本昂贵 (因为 $\Sigma$ 是一个 $n×n$ 的矩阵)             |
| 即使 m 较小，也能顺利运行                                    | 必须保证 m ＞ n，否则 $\Sigma$ 会不可逆，无法计算得到 $p(x)$ 了 【导致 $\Sigma$ 不可逆的另一个原因是存在冗余特征（即线性相关了）】 |

> ![image-20211007212749733](E:\md笔记\PyTorch\images\image-20211007212749733.png)

## 

