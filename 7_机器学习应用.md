# 16 推荐系统

![image-20211008161638546](E:\md笔记\PyTorch\images\image-20211008161638546.png)

## 16.1 问题规划

> 本节讲述推荐系统问题的组成。

以预测电影评分为例。有 5 部电影和 4 个用户，我们要求用户为电影打分。

![image-20211007214039385](E:\md笔记\PyTorch\images\image-20211007214039385.png)

前三部电影是爱情片，后两部则是动作片，我们可以看出**Alice**和**Bob**似乎更倾向与爱情片， 而 **Carol** 和 **Dave** 似乎更倾向与动作片。并且没有一个用户给所有的电影都打过分。**我们希望构建一个算法来预测他们每个人可能会给他们没看过的电影打多少分，并以此作为推荐的依据。**

下面引入一些标记：

$n_u$ 代表用户的数量

$n_m$ 代表电影的数量

$r(i, j)$ 如果用户 $j$ 给电影 $i$ 评过分，则 $r(i,j)=1$

$y^{(i, j)}$ 代表用户 $j$ 给电影 $i$ 的评分

$m_j$ 代表用户 $j$ 评过分的电影的总数

## 16.2 基于内容的推荐算法

> 根据电影内容，将某一部电影推荐给用户。

![image-20211007215014864](E:\md笔记\PyTorch\images\image-20211007215014864.png)

每部电影都有两个特征：

- $x_1$：衡量一部电影为爱情片的程度
- $x_2$：衡量一部电影为动作片的程度

另外，再添加截距 $x_0$，并令 $x_0 = 1$。

下面我们要基于这些特征来构建一个推荐系统算法。假设我们采用线性回归模型，我们可以针对每一个用户都训练一个线性回归模型，如 ${{\theta }^{(1)}}$ 是第一个用户的模型的参数。 于是，我们有：

$\theta^{(j)}$ 表示用户 $j$ 的参数向量

$x^{(i)}$ 表示电影 $i$ 的特征向量

这样，我们预测用户 $j$ 对电影 $i$ 的评分为：$(\theta^{(j)})^T x^{(i)}$.

-- --

针对用户 $j$，该线性回归模型的代价函数为 预测误差的平方和 + 正则化项： 

$$ \min_{\theta (j)}\frac{1}{2}\sum_{i:r(i,j)=1}\left((\theta^{(j)})^Tx^{(i)}-y^{(i,j)}\right)^2+\frac{\lambda}{2}\left(\theta_{k}^{(j)}\right)^2 $$

其中 $i:r(i,j)$ 表示我们只计算那些用户 $j$ 评过分的电影。在一般的线性回归模型中，误差项和正则项应该都是乘以 $1/2m$，在这里我们将 $m$ 去掉，因为它实际不影响最终结果；并且我们不对方差项 $\theta_0$ 进行正则化处理。

上面的代价函数只是针对一个用户的，为了学习所有用户，我们将所有用户的代价函数求和：

 $$ \min_{\theta^{(1)},...,\theta^{(n_u)}} \frac{1}{2}\sum_{j=1}^{n_u}\sum_{i:r(i,j)=1}\left((\theta^{(j)})^Tx^{(i)}-y^{(i,j)}\right)^2+\frac{\lambda}{2}\sum_{j=1}^{n_u}\sum_{k=1}^{n}(\theta_k^{(j)})^2 $$ 

如果我们要用梯度下降法来求解最优解，我们计算代价函数的偏导数后得到梯度下降的更新公式为：

$$ \theta_k^{(j)}:=\theta_k^{(j)}-\alpha\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_{k}^{(i)} \quad (k = 0) $$

$$ \theta_k^{(j)}:=\theta_k^{(j)}-\alpha\left(\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_{k}^{(i)}+\lambda\theta_k^{(j)}\right) \quad (k\neq 0) $$

## 16.3 协同过滤（1）

在之前的基于内容的推荐系统中，对于每一部电影，我们都掌握了关于电影内容的特征变量(动作/爱情的程度)，从而通过对用户打过分的电影的学习来预测用户对未评分的电影的喜爱程度。

现实情况是，我们不可能对每一部电影都给它们手动设置好动作/爱情程度这种特征值，而是仅知道用户对一些电影的评分。这个时候，我们希望根据每个用户对一些电影的评分来学习到这个电影的动作/爱情程度。

假设有一部电影，Rose对它的评价为5星，Jack对它的评价为0星，与此同时，我们又知道Rose喜欢看爱情片，那么我们就可以推断出这部电影是爱情片的可能性为1，是动作片的可能性为0.

假设已知用户的偏好，即用户向我们提供了 $\theta^{(1)},...,\theta^{(n_u)}$，我们想要学习的是特征向量 $x^{(i)}$，那么优化问题应如下：

$min_{x^{(i)}} \frac{1}{2} \sum_{j:r(i,j)=1}((({\theta}^{(j)})^T)x^{(i)} - y^{(i,j)})^2 + \frac{\lambda}{2}\sum_{k=1}^{n}(x_k^{(i)})^2$

> 这个式子与上一节的式子的区别在于：第一个求和符号的下标不同！这里的 $j:r(i,j)=1$ 表明遍历所有用户对电影 $i$ 的评分，最终想要求得电影 $i$ 的特征 $x^{(i)}$. 而上一节式子 $i:r(i,j)=1$ 表明遍历某一个用户对所有电影的评分，最终想要求得用户对未评过分的电影的评分。

上式是如何从一步特定的电影中学习到这个电影的特征(爱情/动作的程度)，下面将其拓展到所有电影：

 $$ \mathop{min}\limits_{x^{(1)},...,x^{(n_m)}}\frac{1}{2}\sum_{i=1}^{n_m}\sum_{j:{r(i,j)=1}}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{\lambda}{2}\sum_{i=1}^{n_m}\sum_{k=1}^{n}(x_k^{(i)})^2 $$ 

**【总结】**

上一节，讲的是，如果你有所有电影评分的集合，以及电影具有的特征向量，那么就可以学习到参数 ${\theta}$。本节，讲的是，如果用户首先为你提供好了参数 ${\theta}$（用户告诉了你他的偏好），那么你就能估计出各种电影的特征值。随机的采取一些 ${\theta}$ 值，从而学习出不同电影的特征 $x$；根据这个 $x$ 得到更好的 ${\theta}$；根据这个 ${\theta}$ 得到更好的 $x$...以此类推，这个过程迭代进行，效果会越来越好，最后收敛于一组合理的电影特征以及一组合理的对不同用户的参数估计。这就是基本的协同过滤算法。

![image-20211008174507869](E:\md笔记\PyTorch\images\image-20211008174507869.png)

> 【应用】这个迭代过程可能使我们得到电影的重要特征，这些特征不总是人能读懂的，但是它确是一个很有意义的特征，比如它可以体现你对一部电影的喜欢与否。我们可以用这些数据作为给用户推荐电影的依据。比如电影 i 有一个特征向量 $x^{(i)}$，另一个电影 j 的特征向量为 $x^{(j)}$，通过计算两向量之间的距离 $||x^{(i)}-x^{(j)}||$ 就可以判断两电影是否相似。如果相似，我们就可以将该电影推荐给用户了。

下一节，我们将对其进行改进，使其在计算时更加高效。

## 16.4 协同过滤（2）

上一节，我们讲到“迭代的计算 $x、{\theta}$”，本节将讲述一种方法可以同时计算 $x、{\theta}$。这种方法就是——将前两个公式结合到一起：

![image-20211008180149126](E:\md笔记\PyTorch\images\image-20211008180149126.png)

【总结——协同过滤算法的步骤】

1. 把 $x、{\theta}$ 初始化为一个比较小的随机值；

2. 使用梯度下降法或其他高级优化算法最小化代价函数：

$$ x_k^{(i)}:=x_k^{(i)}-\alpha\left(\sum_{j:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})\theta_k^{j}+\lambda x_k^{(i)}\right) $$

$$ \theta_k^{(i)}:=\theta_k^{(i)}-\alpha\left(\sum_{i:r(i,j)=1}((\theta^{(j)})^Tx^{(i)}-y^{(i,j)})x_k^{(i)}+\lambda \theta_k^{(j)}\right) $$

3. 根据用户的参数 ${\theta}$ 和电影的特征变量 $x$，预测用户对该电影的评分 $(\theta^{(j)})^Tx^{(i)}$ .

## 16.5 向量化：低秩矩阵分解

> 本节讲解协同过滤算法的向量化实现；以及应用实例。

五个人对五部电影的评分情况如下：

| **Movie**            | **Alice (1)** | **Bob (2)** | **Carol (3)** | **Dave (4)** |
| -------------------- | ------------- | ----------- | ------------- | ------------ |
| Love at last         | 5             | 5           | 0             | 0            |
| Romance forever      | 5             | ?           | ?             | 0            |
| Cute puppies of love | ?             | 4           | 0             | ?            |
| Nonstop car chases   | 0             | 0           | 5             | 4            |
| Swords vs. karate    | 0             | 0           | 5             | ?            |

将以上评分数据表示成矩阵 $Y$：

![image-20211008183139429](E:\md笔记\PyTorch\images\image-20211008183139429.png)

对电影的预测评分可以表示成：

![image-20211008183340028](E:\md笔记\PyTorch\images\image-20211008183340028.png)

用向量表示上式：$X{\Theta}^T$ . 其中：

![image-20211008184423885](E:\md笔记\PyTorch\images\image-20211008184423885.png)

此时，协同过滤算法也被称为低秩矩阵分解，因为 $X{\Theta}^T$ 具有低秩的性质。

## 16.7 实施细节：均值规范化

> 均值规范化是协同过滤算法的预处理步骤，它有时能让你的算法表现得好一些。

让我们来看下面的用户评分数据：

![image-20211008220136128](E:\md笔记\PyTorch\images\image-20211008220136128.png)

如果我们新增一个用户**Eve**，并且**Eve**没有为任何电影评分，那么我们以什么为依据为**Eve**推荐电影呢？

我们首先需要对结果 $Y $ 矩阵进行**均值归一化**处理，将每一个用户对某一部电影的评分减去所有用户对该电影评分的平均值：

![image-20211008220157411](E:\md笔记\PyTorch\images\image-20211008220157411.png)

然后我们利用这个新的 $Y$ 矩阵来训练算法。 如果我们要用新训练出的算法来预测评分，则需要将平均值重新加回去，最终预测值应为 $(\theta^{(j)})^T x^{(i)}+\mu_i$。

其中 $(\theta^{(j)})^T x^{(i)} = 0$，解释如下：

优化目标为：

![image-20211008222243054](E:\md笔记\PyTorch\images\image-20211008222243054.png)

第一项粉色框中的值为0，因为不满足 $r(i,j)=1$；==第二项蓝色框不起作用==（就不需要考虑特征了，只需要考虑可能的评分、权重而已）；所以最后这个优化目标就只有最后一项在起作用，整个含义变成了：我们想选一个向量 ${\theta}^{(5)}$ 使得最后的正则化项尽可能的小，即使得 $\frac{\lambda}{2}(({\theta}_1^{(5)})^2+({\theta}_2^{(5)})^2)$ 尽可能的小，那么只能取 ${\theta}^{(5)}$ 为**0向量**。

所以对于**Eve**，我们的新模型会认为她给每部电影的评分都是该电影的平均分。

# 17 大规模机器学习

## 17.1 大型数据集的学习

为什么要使用到非常庞大的数据集？我们已经知道，一种获取高性能的机器学习系统的途径是采用低偏差的学习算法，并用大数据进行训练。大数据集学习的问题是计算量大。比如对于一个训练集样本数 $m=100,000,000$ 的训练算法来说，执行梯度下降步骤（${\theta}_j := {\theta}_j - {\alpha}\frac{1}{m}(h_{\theta}(x^{(i)})-y^{(i)})x_j^{(i)}$）就需要 $100,000,000$ 次。接下来，我们会讲解某个能够替代这个算法的算法或是寻找更有效的计算这个导数的方法。

如果用小数据集与使用大数据集训练出来的效果差不多，那就没必要使用大数据集。所以，应该提前通过绘制**学习曲线**来检查是否有必要使用大数据集。

后面，我们主要讲解两个办法来处理海量数据：随机梯度下降和减少映射。

## 17.2 随机梯度下降

以线性回归为例，一般的梯度下降法（批量梯度下降）如下：

![image-20211009091618444](E:\md笔记\PyTorch\images\image-20211009091618444.png)

在随机梯度下降法中，我们定义一个衡量单个训练样本的代价函数：

 $$cost\left( \theta, \left( {x}^{(i)} , {y}^{(i)} \right) \right) = \frac{1}{2}\left( {h}_{\theta}\left({x}^{(i)}\right)-{y}^{{(i)}} \right)^{2}$$

**随机**梯度下降算法：

1. 对训练集随机“洗牌”，打乱所有数据

2.  **Repeat** **{**

   ​		**for** $i = 1:m$ **{**

   ​	 		${\theta}_j:= {\theta}_j - {\alpha}\frac{{\partial} cost}{{\partial}{\theta}_j } = {\theta}_{j}-\alpha\left( {h}_{\theta}\left({x}^{(i)}\right)-{y}^{(i)} \right){{x}_{j}}^{(i)}$

   ​			 	**(for every** j = 0, ..., n**)**

     	   **}** 

     **}**

   > i 代表第 i 个训练样本；j 代表样本的参数向量中的第 j 个元素。$\frac{\partial blabla}{\partial blabla}$

比较一般的梯度下降算法与随机梯度下降算法中**“Repeat”**的这一步里的代码：

随机梯度下降实际上就是遍历所有的训练样本，然后针对遍历出来的**单个样本的代价函数**进行梯度下降操作，每次都只关注一个训练样本，使其对这单个训练样本拟合的更好，最终全部遍历下来的，就能够拟合到对所有训练样本都比较友好的参数了。而对于一般的梯度下降算法，需要对全部 $m$ 个样本求和来得到梯度项 $\sum_{i=1}^m({h}_{\theta}({x}^{(i)})-{y}^{(i)}){{x}_{j}}^{(i)}$。

批量梯度下降会取一条合理的直线来达到全局最小值（下图红色线）。而对于随机梯度下降，每一次迭代只考虑一个样本，所以得到/接近最小值的过程比较“曲折”（下图粉色线）。

<img src="E:\md笔记\PyTorch\images\image-20211009095620992.png" alt="image-20211009095620992" style="zoom:67%;" />

随机梯度下降算法中**“Repeat”**通常是使其重复1—10次。

## 17.3 Mini-Batch 梯度下降

> 小批量梯度下降有时甚至比随机梯度下降还要快。

小批量梯度下降算法是介于批量梯度下降算法和随机梯度下降算法之间的算法：

- 批量梯度下降算法：在一次迭代中需要使用所有的 m 个训练样本

- 小批量梯度下降算法：在一次迭代中使用 b （通常，令 2 ≤ b ≤ 100）个训练样本

- 随机梯度下降算法：在一次迭代中只使用1个训练样本

> 每次迭代的过程都是在训练参数。

具体如下：

**Repeat {**

​	**for** $i = 1: m-b+1$ **{**

​			${\theta}_j := {\theta}_j - {\alpha}\frac{1}{b}\sum_{k=i}^{i+b-1}(h_{\theta}(x^{(i)})-y^{(i)})x_j^{(i)}$

​					 (**for** $j=0:n$)

​		 	$ i += b $

​	 **}**

 **}**

实例：

![image-20211009103438745](E:\md笔记\PyTorch\images\image-20211009103438745.png)

Mini-Batch梯度下降的一个缺点是：当有一个额外的参数b时，你需要确定这个b的大小。

## 17.4 随机梯度下降收敛

如何确保随机梯度下降算法已经达到最优值？如何确定学习速率 ${\alpha}$ ？

对于批量梯度下降，我们可以绘制一个代价函数 $J_{train}({\theta})=\frac{1}{2m}\sum_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)})^2$ 随迭代次数的变化而变化的图像，根据该图像可以判断梯度下降是否收敛。问题在于，数据太大时，我们不希望时不时的就要遍历所有数据来计算 $J$。

对于随机梯度下降，我们是每次都对单个训练样本进行拟合，所以可以在每次将要对某个样本使用梯度下降进行拟合时，就先计算我们已经得到的模型在这个样本上的预测误差 $cost({\theta}, (x^{(i)}, y^{(i)}))=\frac{1}{2}(h_{\theta}(x^{(i)})-y^{(i)})^2$。最后，为了检查出随机梯度下降是否收敛，我们可以每1000次迭代就画出这1000次计算得到的代价函数的平均值。下面是几个例子：

1， ![image-20211009113155924](E:\md笔记\PyTorch\images\image-20211009113155924.png)

这是每组含有1000个样本时得到的每组代价函数的平均值与迭代次数之间的关系图，整体呈现代价函数在下降的趋势且最后趋于平缓/收敛，这是我们想要的效果。红色曲线的 ${\alpha}$ 值比蓝色曲线的 ${\alpha}$ 值小，所以算法的学习变得更慢了，代价函数下降速度也变小了；但最后更能使算法收敛到一个更好的结果。

2，![image-20211009113720151](E:\md笔记\PyTorch\images\image-20211009113720151.png)

蓝色曲线仍然是每组含有1000个样本得到的代价函数的平均值，而红色曲线是每组含有5000个样本，这将使得红色曲线比蓝色曲线更平滑；不过组内含有的样本数多也有一个缺点：也许算法早就已经收敛了，但是算法还会继续执行，也就是对收敛速度的感知变弱了。

3，![image-20211009114038492](E:\md笔记\PyTorch\images\image-20211009114038492.png)

如果蓝色曲线为上图这样，这表明代价函数似乎完全没有在减小，即算法并没有在有效学习；但如果在此基础上增加每组中含的训练样本数，那么可能会得到红色曲线。

4，![image-20211009114351786](E:\md笔记\PyTorch\images\image-20211009114351786.png)

如果得到的图像如上图所示，代价函数在上升，这表明算法发散，这时你应该使用更小的学习速率 ${\alpha}$ .

-- --

【关于学习速率 ${\alpha}$】

在大多数随机梯度下降法的典型应用中， ${\alpha}$ 一般是一个固定的值，这就会使我们得到一个全局最小值的接近值（在最小值附近徘徊）：

<img src="E:\md笔记\PyTorch\images\image-20211009114932348.png" alt="image-20211009114932348" style="zoom:50%;" />

为了更好地得到全局最小值的准确值，我也可以令学习率随着迭代次数的增加而减小，例如令： $$\alpha = \frac{const1}{iterationNumber + const2}$$，其中，常数 $const1, const2$ 需要我们花时间手动确定。效果如下：

<img src="E:\md笔记\PyTorch\images\image-20211009115323953.png" alt="image-20211009115323953" style="zoom:50%;" />

> 通常我们直接令 ${\alpha}$ 为一个固定的值便能有非常好的效果了。

## 17.5 在线学习

**在线学习机制**——一种新的大规模的机器学习机制，它可以让我们**模型化问题**；模型化问题指的是让算法从<font color="blue">连续一波数据</font>或<font color="blue">连续的数据流</font>中学习的问题。

今天，许多大型网站或者许多大型网络公司，使用不同版本的在线学习机制算法，从大批的涌入又离开网站的用户身上进行学习。特别要提及的是，如果你有一个由连续的用户流引发的连续的数据流，进入你的网站，你能做的是使用一个在线学习机制，从数据流中学习用户的偏好，然后使用这些信息来优化一些关于网站的决策。

假定你有一个提供运输服务的公司，用户们来向你询问把包裹从**A**地运到**B**地的服务，同时假定你有一个网站，让用户们可多次登陆，然后他们告诉你，他们想从哪里寄出包裹，以及包裹要寄到哪里去，也就是出发地与目的地，然后你的网站开出运输包裹的的服务价格，然后根据你开给用户的这个价格，用户有时会接受这个运输服务，那么这就是个正样本，有时他们会拒绝购买你的运输服务。所以，让我们假定我们想要一个学习算法来帮助我们优化想给用户开出的价格。（再比如饿了么的红包？第一天给我5元，我没有点餐；于是第二天给我8元...）

模型化问题**在线学习**算法指的是对在线的、动态的数据流而非离线的、静态的数据集的学习。许多在线网站都有持续不断的用户流，对于每一个用户，网站希望能在不将数据存储到数据库中便顺利地进行算法学习。

-- --

假使我们正在经营一家物流公司，每当一个用户询问从地点**A**至地点**B**的快递费用时，我们给用户一个报价，该用户可能选择接受（$y=1$）或不接受（$y=0$）。

现在，我们希望构建一个逻辑回归模型，来预测用户接受报价使用我们的物流服务的可能性。因此 [报价] 是我们的一个特征，其他特征为距离、起始地点、目标地点以及特定的用户数据。模型的输出是用户接受的概率：$p(y=1)$。

**在线学习的算法**与随机梯度下降算法有些类似：对单一的实例进行学习，而非对一个提前定义的训练集进行循环；区别在于，在线学习算法所使用的数据是动态变化的。

**Repeat forever (as long as the website is running) {** 

​		Get $\left(x,y\right)$ corresponding to the current user 	

​		$\theta:={\theta}*{j}-\alpha\left( {h}*{\theta}\left({x}\right)-{y} \right){{x}_{j}}$ 

​		(**for** $j=0:n$) 

**}**

一旦对一个数据的学习完成了，我们便可以丢弃该数据，不需要再存储它了。这种方式的好处在于，我们的算法可以很好的适应用户的倾向性，算法可以针对用户的当前行为不断地更新模型以适应该用户。

【实际应用：点击率(Click-through Rate, 简称CTR)预测学习问题】

> ![image-20211009134251702](E:\md笔记\PyTorch\images\image-20211009134251702.png)

## 17.6 并行 & Map-reduce

映射化简和数据并行对于大规模机器学习问题而言是非常重要的概念。之前提到，如果我们用批量梯度下降算法来求解大规模数据集的最优解，我们需要对整个训练集进行循环，计算偏导数和代价，再求和，计算代价非常大。

改进：将大数据集分配给多台计算机，让每一台计算机处理数据集的一个子集，然后再将计算的结果汇总在求和。这样的方法叫做**映射简化（Map-reduce）**。

![image-20211009135710476](E:\md笔记\PyTorch\images\image-20211009135710476.png)

具体而言，如果学习算法能够表达为 [ 对训练集的函数的求和 ]，那么便能将这个任务分配给多台计算机（或者同一台计算机的不同 **CPU** 核心），以达到加速处理的目的。

例如，我们有400个训练实例，我们可以将批量梯度下降的求和任务分配给4台计算机进行处理：

![image-20211009135031816](E:\md笔记\PyTorch\images\image-20211009135031816.png)

很多高级的线性代数函数库已经能够利用多核**CPU**的多个核心来并行地处理矩阵运算，这也是算法的**向量化**实现如此重要的缘故（比调用循环快）。

# 18 机器学习应用实例：OCR

> 本章涉及：
>
> - 一个复杂的机器学习系统是如何被组合起来的？
> - 如何分配资源？
> - 如何将机器学习应用到计算机视觉？
> - 机器学习流水线（pipeline）的有关概念
> - 人工数据合成的概念

## 18.1 问题描述和流程图

**图片光学字符识别**（**Optical Character Recognition**, 简称**OCR**）问题：从一张给定的图片中识别文字（这比从一份扫描文档中识别文字要复杂的多）。

![image-20211009141944227](E:\md笔记\PyTorch\images\image-20211009141944227.png)

> 应用：为盲人提供一个照相机，这个照相机能够看出他们前面有什么东西，比如可以告诉盲人前面有一个路牌；导航系统——想象你的车能读出街上的路牌，帮你导航到目的地。

为了实现照片OCR，需要采取如下步骤：

1. 文字侦测（**Text detection**）——将图片上的文字与其他环境对象分离开来
2. 字符切分（**Character segmentation**）——将文字分割成一个个单一的字符
3. 字符分类（**Character classification**）——确定每一个字符是什么 

> ![image-20211009142949742](E:\md笔记\PyTorch\images\image-20211009142949742.png)

可以将这一过程称之为机器学习流水线，流水线中有多个不同的模块，表示如下：

![image-20211009143138477](E:\md笔记\PyTorch\images\image-20211009143138477.png)

对于一个机器学习工程来说，可以按照模块进行分工合作，比如**Text detection**模块需要1-5人。

### 18.2 滑动窗口

> 讲解流水线中每个独立的组件的工作原理。

本节主要讲解一种叫做滑动窗口分类器的东西。

滑动窗口是一项用来从图像中抽取对象的技术。假使我们需要在一张图片中识别行人，首先要做的是用许多固定尺寸的图片来训练一个能够准确识别行人的模型。然后我们用之前训练识别行人的模型时所采用的图片尺寸在我们要进行行人识别的图片上进行剪裁；然后将剪裁得到的切片交给模型，让模型判断是否为行人，然后在图片上滑动剪裁区域重新进行剪裁（滑动的距离通常称为**步长**，单位为像素），将新剪裁的切片也交给模型进行判断，如此循环直至将图片全部检测完。然后我们按比例放大剪裁的区域，即以新的尺寸对图片进行剪裁，将新剪裁的切片按比例缩小至模型所采纳的尺寸，交给模型进行判断，如此循环。最终算法将能检测出图中各个地方是否出现行人。

![image-20211009150220233](E:\md笔记\PyTorch\images\image-20211009150220233.png)

这就是如何训练一个监督学习分类器，然后使用一个滑动窗口分类器/检测器来找出图中的所有行人。

滑动窗口技术也被用于文字识别，首先训练模型使其能够区分字符与非字符，然后，运用滑动窗口技术识别字符。完成字符识别后，需要对识别出的区域进行一些扩展，然后将重叠的区域进行合并。接着我们以宽高比作为过滤条件，过滤掉高度比宽度更大的区域（认为单词的长度通常比高度要大）。下图中绿色的区域是经过这些步骤后被认为是文字的区域，而红色的区域是被忽略的。

![image-20211009150903585](E:\md笔记\PyTorch\images\image-20211009150903585.png)

以上便是文字侦测阶段。 下一步是训练一个模型来完成将文字分割成单个字符的任务，需要的训练集为：单个字符的图片（$y=0$）和两个相连字符之间的图片（$y=1$），如下图。

![image-20211009151343474](E:\md笔记\PyTorch\images\image-20211009151343474.png)

在滑动窗口移动的过程中就只能出现两种情况：滑动窗口部分是单个字符、滑动窗口部分是两个两个相连字符的中间部分。所以每次滑动到一个窗口时，模型就对它进行判断，得出结果 $y=1$ 或 $y=0$。最终即可把所有单个字符找出来。

![image-20211009152316799](E:\md笔记\PyTorch\images\image-20211009152316799.png)

最后一个阶段是字符分类阶段，利用神经网络、支持向量机或者逻辑回归算法训练一个分类器即可。

### 18.3 人工数据合成

如果我们的模型是低方差的，那么获得更多的数据用于训练模型，是能够有更好的效果的。问题在于，我们怎样获得数据，数据不总是可以直接获得的，我们有可能需要人工地创造一些数据。

人工数据合成主要有两种形式：

- 自己创造数据，即从零开始创造新数据。

  > 以我们的文字识别应用为例，我们可以在字体网站上下载各种字体，然后利用这些不同的字体配上各种不同的随机背景图片创造出一些用于训练的实例，这让我们能够获得一个无限大的训练集。这是从零开始创造实例。

- 对已有数据进行修改。

  > 1. 例如将已有的字符图片进行一些扭曲、旋转、模糊处理。只要我们认为实际数据有可能和经过这样处理后的数据类似，我们便可以用这样的方法来创造大量的数据。
  > 2. 语音识别实例如何扩充数据集？通过人工添加失真，对原有的语音里加入一些背景音，比如蜂鸣声。
  >
  > 【注意】即便是对原有的数据进行修改，也应该做出有意义的修改，否则新增的数据不会有多大帮助。

有关获得更多数据的几种方法：

1. 人工数据合成
2. 手动收集、标记数据
3. 众包

### 18.4 上限分析：接下来做什么

> - 不要花费时间做一些没有意义、对结果帮助不大的事情！
>
> - 上限分析（ceiling analysis）：指导你开发机器学习应用时，应在哪方面花费时间。

在机器学习的应用中，我们通常需要通过几个步骤才能进行最终的预测，我们如何能够知道哪一部分最值得我们花时间和精力去改善呢？这个问题可以通过**上限分析**来回答。

回到我们的文字识别应用中，我们的流程图如下：

![image-20211009160554533](E:\md笔记\PyTorch\images\image-20211009160554533.png)

我们想知道流程图中的哪一步最需要花费时间或资源，并且希望可以使用一个数值评价量度进行度量。例如，给定一个测试样本图像，那么这个数值就表示我们对测试图像中的文本识别正确的比例。当然，你也可以选择其他某个数值评价度量值。

假使整个系统目前的准确率为72%。下限分析的思想是：首先关注这个机器学习工作流中的第一个模块——文本检测，对于每一个测试样本，都给它提供一个正确的文本检测结果，换句话说，我们要遍历每个测试集样本，然后人为地告诉算法每一个测试样本中文本的位置。然后把这些真实的文本位置的标签输出，作为下一模块——字符分割的输入。在这种情况下，再次检测出整个系统的准确率，假设提升到了89%。下面，我们还直接将真实的字符分割结果直接传给下一阶段——字符识别，然后再次检测出整个系统的准确率，假设提升到了90%。最后仍然人工给出字符识别这一模块的正确标签，那么系统准确率就变成100%。

上限分析完成后，我们就知道提升某个模块后对整个系统的准确率的影响了，即上升空间：如果我们有了完美的文本检测模块，那么整个系统的准确率将提升17%；之后，如果我们有了完美的字符分割模块，也只能使系统的准确率提升1%；再之后，如果我们有了完美的字符识别模块时，可使系统准确率提升10%。综上，最应该在文本检测模块的优化上花费时间。

另一个例子。假设你要识别图中的人是否是你的朋友，我们设计了如下的工作流：

![image-20211009163725388](E:\md笔记\PyTorch\images\image-20211009163725388.png)

对于这个流水线，应该怎样做上限分析？

我们还是每次只关注一个步骤。假设当前整个系统的准确率为85%，首先还是找到测试集，然后人工的给它真实的标签；然后到了第二步，我们使用PS手动将背景去除，然后重新计算整个系统的准确率，假设提高了0.1%。之后，给出正确的脸部识别图案，准确率提高了5.9%；接下来依次运行眼睛、鼻子和嘴巴的分割，分别给出眼睛、鼻子、嘴巴的正确位置，假设准确率分别提高了4%, 1%, 1%。最后，再给出最终的正确标签，准确率提高到100%。准确率变化如下：

![image-20211009164953050](E:\md笔记\PyTorch\images\image-20211009164953050.png)

经过这样的上限分析后，知道最应该花费精力进行优化的模块是脸部检测。

# 19 结束语

![image-20211009165554086](E:\md笔记\PyTorch\images\image-20211009165554086.png)