> - 学习资源来自==《神经网络PyTorch实战》(肖智清)== .
> - 先完成的笔记是《PyTorch神经网络搭建流程总结》，在看那本书时，很多底层的东西没有讲到。这里的笔记会涉及！会变得更明白！（所以我更想把这篇放在《PyTorch神经网络搭建流程总结》前面，但初学者想赶快看下效果的话，也是可以先看那一篇的）
> - 学完“求解优化问题”这一节就可以知道`backward()`到底做了什么。

# 迷你AlphaGo的代码实现
### 理论基础
- Linear类表示一层神经网络，这层神经网络上可能有多个神经元，并且每个神经元的输入都是一样的。在使用Linear类的时候，需要指定每个神经元有几个输入，这个层有多少个神经元。通过调用Linear类，并在调用过程中指定每个神经元的输入个数和神经元的个数，就可以确定部分神经网络的结构。
- ReLU类表示`max(·,0)`这个运算。通过调用ReLU类，就可以指定神经元的非线性函数是什么。
### 实现目标
对任意的X=(x[0], x[1], x[2])，找到合适的y，使得函数g的值最大。
### 实现逻辑
用一个人工神经网络来代替从X=(x[0], x[1], x[2])到y的关系。通过设计人工神经网络的结构、确定合适的参数，使得这个人工神经网络可以实现从X到y的最优关系的形式。

值得一提的是，由于*不知道函数g的具体形式*，所以也不知道从X到y的最优关系的形式。实际上，从X到y的关系甚至可能没有显式表达式。这再一次体现了人工神经网络的强大之处：**我们不需要知道解答的形式，只需要搭建人工神经网络；我们不需要告诉机器神经网络中神经元的权重都是多少，PyTorch可以帮助找到神经元的权重。**
### 实现代码
```python
import torch
from torch.optim import Adam
from torch.nn import Linear, ReLU, Sequential


# 1、确定神经网络的结构
net = Sequential(
    Linear(3, 8),  # 第一层有8个神经元
    ReLU(),        # 第一层神经元的非线性函数是max(., 0)
    Linear(8, 8),  # 第二层有8个神经元
    ReLU(),        # 第二层神经元的非线性函数是max(., 0)
    Linear(8,1)    # 第三层有1个神经元
)


# 2、构造测试函数g(神经网络权重的确定和函数g有关。函数g不同，神经网络就需要不同的权重值)
def g(x, y):
    x0, x1, x2 = x[:, 0]**0, x[:, 1]**1, x[:, 2]**2 # x[:, 0]表示截取x矩阵每一行的第0列元素
    y0 = y[:, 0]
    return (x0+x1+x2)*y0 - y0*y0 - x0*x1*x2


# 3、使用优化器确定人工神经元的权重值(优化器每次可以改良所有权重值；需要让优化器反复改良很多次才能让神经网络的所有权值都合适)
optimizer = Adam(net.parameters())
for step in range(1000):
    optimizer.zero_grad()
    x = torch.randn(1000, 3)
    y = net(x)
    outputs = g(x, y)
    loss = -torch.sum(outputs)
    loss.backward()
    optimizer.step()
    if step % 100 == 0:
        print('第{}次迭代损失 = {}'.format(step, loss))


# 4、测试人工神经网络的效果
# 4.1 生成测试数据
x_test = torch.randn(2, 3)
# 4.2 查看神经网络的计算结果
y_test = net(x_test)
print('人工神经网络计算结果：{}'.format(y_test)) 
print('g的值：{}'.format(g(x_test, y_test)))
# 4.3 计算理论最优结果作为参考(与使用人工神经网络计算出来的结果进行对比)
def argmax_g(x):
    x0, x1, x2 = x[:, 0]**0, x[:, 1]**1, x[:, 2]**2
    return 0.5*(x0+x1+x2)[:, None]
yref_test = argmax_g(x_test)
print('理论最优值：{}'.format(yref_test))
print('g的值：{}'.format(g(x_test, yref_test)))
```

### 运行结果
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210427171650287.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5X3oxMTEyMQ==,size_16,color_FFFFFF,t_70)
# 求解优化问题 
## 使用PyTorch计算梯度数值
### 理论基础
在PyTorch中，只要指定自变量、函数，就可以得到梯度的数值。使用PyTorch计算梯度的数值有两大要点：
- 实例化`torch.Tensor`类时，要设置参数`requires_grad=True`。只有这样，PyTorch在求梯度时才会考虑它。
- 调用张量类实例的成员方法`backward()`可以告诉PyTorch要对哪个函数求偏导。调用完`backward()`后，自变量的成员数据`grad`就存储了求得的偏导的数值。

### 实现目标
计算$f(X) = -(cos^2x[0] + cos^2x[1])^2$在`(x[0], x[1]) = (π/3, π/6)`处的梯度。
### 实现代码
```python
# 使用PyTorch计算梯度数值
from math import pi
import torch


x = torch.tensor([pi/3, pi/6], requires_grad=True)
f = -((x.cos() ** 2).sum()) ** 2  # 求得在给定点处的函数值
print(f'value = {f}')

f.backward()  # 求得在给定点x处的梯度值
print(f'grad = {x.grad}')
```
### 运行结果
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210427180832179.png)
## 梯度下降算法
### 理论基础
对于某个自变量，如果自变量顺着梯度的方向改变一些，那么函数值就可能变大；如果自变量逆着梯度方向改变一些，那么函数值就可能变小。**梯度下降（gradient descent）算法**就是利用这一个原理求解函数的最小值。
> 是啊，怪不得每次代码都写的是`loss.backward()`，因为我们希望损失值越来越小啊。

事实上，如果能让任意函数的值尽可能小，就能让任意函数的值尽可能大。因为，要让函数的值尽可能大，则相当于让函数值的负值尽可能小。

梯度下降算法是一个**迭代算法**。开始时（ t = 0 ），算法随便指定一个初始张量值 $X_0$ 和一个学习速率 $η$。每次迭代，都反复执行以下步骤：在第 t 次迭代开始前（t = 1, 2, ... , 这里，t 从 1 开始与 PyTorch 的内部实现有关），自变量张量值为 $X_{t-1}$，基于这个自变量值计算出的梯度值为 $∇f(X_{t-1})$。基于算出的梯度值，用下式更新自变量：
$$X_t = X_{t-1} - η∇f(X_{t-1})$$.

由于自变量逆着梯度方向改变，所以函数的值很可能下降。

原始梯度下降算法的缺陷和解决方案：
1. 基本的梯度下降算法容易陷入局部极小值，甚至陷入鞍点。误以为已经找到了最小值。---> 解决方法：引入“**动量**”
2. 基本的梯度下降算法可能会在最优点附近震荡但始终无法有效接近最优点。---> 解决方法：**动态调整学习速率**

`torch.optim`包中提供了非常多的实现**参数自动优化**的类（即实现了梯度下降的逻辑），比如SGD、AdaGrad、RMSProp、Adam等。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210427195746340.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5X3oxMTEyMQ==,size_16,color_FFFFFF,t_70)

### 代码实现
以`torch.optim.SGD`类为例，利用梯度下降法最小化函数$f(X) = -(cos^2x[0] + cos^2x[1])^2$。具体使用流程见代码。

```python
# 0. 导入需要使用到的库
import torch.optim
from math import pi
import torch

# 指定初始自变量值 x1=pi/3、x2=pi/6，并将它们保存到特定变量中
x = torch.tensor([pi/3, pi/6], requires_grad=True)

# 1. torch.optim.SGD 类实现了梯度下降算法，因此我们对它进行实例化，方便后续使用
optimizer = torch.optim.SGD([x, ], lr=0.1, momentum=0)  # 指定学习率为 0.1

for step in range(11):  # 迭代 11 次
    if step:
        # 2. 清空优化器在上次迭代中存储的数据
        optimizer.zero_grad()
        # 3. 对函数 f 求解梯度
        f.backward()
        # 4. 更新自变量 x1、x2的值
        optimizer.step()
    f = -((x.cos() ** 2).sum()) ** 2
    print(f'step {step}: x = {x.tolist()}, f(x) = {f}')
```



```python
import torch.optim
from math import pi
import torch


x = torch.tensor([pi/3, pi/6], requires_grad=True)


# 1. 实例化torch.optim.SGD类
optimizer = torch.optim.SGD([x, ], lr=0.1, momentum=0)

for step in range(11):
    if step:
        # 2. 清空优化器在上次迭代中存储的数据
        optimizer.zero_grad()
        # 3. 求解梯度
        f.backward()
        # 4. 更新自变量的值
        optimizer.step()
    f = -((x.cos() ** 2).sum()) ** 2
    print(f'step {step}: x = {x.tolist()}, f(x) = {f}')
```
> `step`变量从0开始迭代，为0时，不执行if语句中的内容，算是初始化了`f`。


### 运行结果
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210427191430787.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5X3oxMTEyMQ==,size_16,color_FFFFFF,t_70)
> 结论：的确得到f(x)的最小值（为-4）. 说明用梯度下降算法使一个函数最小化是可以的。

## 实例：Himmelblau函数的优化
### Himmelblau函数及可视化
Himmelblau函数是一个自变量大小为(2, )的4次函数，它得名于数学家David Himmelblau。该函数常用于**测试优化器的性能**。Himmelblau函数的表达式：$f(X) = ((x[0])^2 + x[1] -11)^2 + (x[0] + (x[1])^2 - 7)^2$.

```python
import numpy as np
from mpl_toolkits.mplot3d import Axes3D  # 尽管并没有使用但必须导入，且必须在导入matplotlib之前运行，只有这样才能支持三维图表的绘制
import matplotlib.pyplot as plt
from matplotlib import cm
from matplotlib.colors import LinearSegmentedColormap


# Himmelblau函数的实现
def himmelblau(x):
    return (x[0] ** 2 + x[1] - 11)**2 + (x[0] + x[1] ** 2 - 7)**2


# 准备数据
x = np.arange(-6, 6, 0.1)  # x轴的采样点（一维）
y = np.arange(-6, 6, 0.1)  # y轴的采样点（一维）
X, Y = np.meshgrid(x, y)   # 将x轴和y轴的采样点整合起来，得到二维的采样点。这些二维的采样点表示了整个自变量空间
Z = himmelblau([X, Y])     # 调用himmelblau()，得到自变量空间上每个样点对应的函数值


# 绘制图表
fig = plt.figure()
ax = fig.gca(projection='3d')  # 获得Axes3D的类实例ax
ax.plot_surface(X, Y, Z)       # 绘制表面图(X、Y、Z轴)
ax.view_init(60, -30)          # 指定用什么视角来观察这个三维图——view_init(仰角的角度值, 方位角的角度值)
ax.set_xlabel('x[0]')
ax.set_ylabel('x[1]')
fig.show()
```
### 求解Himmelblau的极小值
由图像知Himmelblau函数有4个极小值。下面使用`torch.optim.Adam`来求解这些极小值。
```python
import torch
x = torch.tensor([0., 0.], requires_grad=True)  # 张量x的初始值为(0, 0)【设置不同的初始值会得到不同的最优解】，设置requires_grad=True表示求梯度时需要考虑该变量
optimizer = torch.optim.Adam([x, ])  # 选择优化器，并告诉优化器哪些是要优化的决策变量
for step in range(20001):  			 # 迭代优化
    if step:
        optimizer.zero_grad()
        f.backward()
        optimizer.step()
    f = himmelblau(x)
    if step % 1000 == 0:
        print(f'step {step}: x = {x.tolist()}, f(x) = {f}')
```
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210428095816894.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5X3oxMTEyMQ==,size_16,color_FFFFFF,t_70)
> 说明：改变`x`的初始值，可以求得其他的极小值点。如将`x`的初始值再分别改为(-1, 0)、(-4, 0)、(4,0)。
### 求解Himmelblau的局部极大值
Himmelblau函数有4个最小值点，但是没有最大值点。这是因为Himmelblau函数可以任意大。但是函数在(-0.27, -0.92)附近有一个局部极大值。

本节使用`torch.optim.Adam`来找到这个局部极大值。

由于`torch.optim`子包里的优化器都是试图最小化函数的值，所以要对函数值取符号。对函数值取符号后求得的梯度值，与不取负号得到的梯度值正好相反。

只需把上一小节中的代码：
```python
f.backward()
```
改为：
```python
(-f).backward()
```
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210428103237621.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5X3oxMTEyMQ==,size_16,color_FFFFFF,t_70)

> 以上，你学会了如何最小化或最大化任意的函数。

# 回归问题（线性回归）
## 引入
回归的目的是找到自变量和因变量之间的关系。最简单的回归：线性回归。
> “自变量”其实就是特征，因变量其实就是“标签”。特征张量通常是一个二维数组，一行代表一条数据(自变量)，一行中的每个数据代表这个自变量的每个特征。标签张量是只有一列的二维数组，每一行对应的就是特征张量每一行的自变量对应过来的因变量（该特征下，该数据所属的类别）。

线性回归相当于神经网络中神经元的线性叠加运算，而线性叠加运算是神经网络中不可或缺的运算。
## 一元线性回归
谈及m个自变量x[0], x[1], ..., x[m-1]和因变量y之间的关系，线性关系是最简单的关系之一。线性关系具有如下形式：$y = x[0]w[0] + x[1]w[1] + ... + x[m-1]w[m-1] + w[m]$. 其中，w[0], w[1], ..., w[m-1], w[m]是m+1个权重值。

**线性回归就是假设自变量和因变量之间的关系具有这样的关系式，再利用数据确定出这m+1个权重值，最终找到自变量和因变量之间的关系。**

### 最小二乘法
最小二乘法（Linear Least Squares, LLS）是一种最基本的线性回归方法。[PyTorch中的](https://pytorch.org/docs/stable/generated/torch.lstsq.html#torch.lstsq)函数`torch.lstsq(特征张量Y，标签张量X)`实现了最小二乘法。该函数有两个返回值：
- 一个含有权重数据、残差的张量
- QR分解(QR Decomposition)的结果(这些结果对最小二乘法的进一步分析有帮助)
> - 当X的大小为(n, m+1)，Y的大小为(n,)，则返回的权重值是一个大小为(n,1)的张量。取这个张量的前m+1个元素，就可以得到大小为(m+1,)的权重张量W。而这前m+1个元素之外的元素是表示残差的量，它们的平方和正是均方误差（Mean Squared Error，MSE）的值。
> - 最小二乘法用MSE表示Y和X·W(表示矩阵X和矩阵W点积，就“一元线性回归”那里的式子)的接近程度。
> - **线性回归，就是试图找到权重值W，使得Y和X·W尽可能接近。**

实例代码：
```python
import torch

x = torch.tensor([[1., 1., 1.], [2., 3., 1.], [3., 5., 1.], [4., 2., 1.], [5., 4., 1.]])
y = torch.tensor([-10., 12., 14., 16., 18.])
wr, _ = torch.lstsq(y, x)
w = wr[:3]
print(w)
```
![在这里插入图片描述](https://img-blog.csdnimg.cn/2021042811580171.png)

### 正规方程法
正规方程（Normal Equation）法是最常见的求解最小二乘的方法。利用正规方程法，只要将数据代入公式(导数定义，令梯度为0，解出自变量的值)，就可以得到最小二乘的权重值。从这个意义上看，正规方程法简单有效。因此，*正规方程法是求解最小二乘最经典的方法*。不过，正规方程法是基于最小二乘推导得到的，它只对MSE损失适用。对于其他类型的损失，需要另找办法。
## 多元线性回归
多元线性回归试图讨论自变量与多个因变量之间的关系。

实例代码：
```python
import torch

x = torch.tensor([[1., 1., 1.], [2., 3., 1.], [3., 5., 1.], [4., 2., 1.], [5., 4., 1.]])
y = torch.tensor([[-10., -3.], [12., 14.], [14., 12.], [16., 16.], [18., 16.]])
wr, _ = torch.lstsq(y, x)
w = wr[:3, :]
print(w)
```
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210428115944921.png)
## 使用梯度下降法求解线性回归问题
### 理论基础1：损失函数
除了MSE损失，还有其他损失，如$l_1$损失【也叫平均偏差(Mean Absolute Deviance, MAD)】、平滑$l_1$损失【也叫Huber损失】。PyTorch在`torch.nn`子包中实现了多种损失，比如`torch.nn.MSELoss`、`torch.nn.L1Loss`、`torch.nn.SmoothL1Loss`就分别对应刚才的三个损失。

`torch.nn`子包里的损失类都是`torch.nn.Module`扩展类的子类。

### 代码实现1
```python
import torch
import torch.nn
import torch.optim


x = torch.tensor([[1., 1., 1.], [2., 3., 1.], [3., 5., 1.], [4., 2., 1.], [5., 4., 1.]])
y = torch.tensor([-10., 12., 14., 16., 18.])
w = torch.zeros(3, requires_grad=True)

# 1. 构造损失类的实例对象
criterion = torch.nn.MSELoss()
optimizer = torch.optim.Adam([w, ], )

for step in range(30001):
    # 3. 用梯度下降法使损失最小(对损失求梯度)，并据此更新w的值
    if step:
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    pred = torch.mv(x, w)  # 张量x与张量w作点积运算；预测结果pred是权重的函数，后续要对其求梯度
    # 2. 调用损失类的实例对象(参数1为预测结果，参数2为标签)
    loss = criterion(pred, y)
    if step % 1000 == 0:
        print('step = {}, loss = {:g}, W = {}'.format(step, loss, w.tolist()))
```
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210428130240420.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5X3oxMTEyMQ==,size_16,color_FFFFFF,t_70)

最后的结果就和前面"一元线性回归"一节中用`torch.lstsq()`求得的是一样的。相比起来，这里更加费时费力。所以，对于`torch.lstsq()`可以解决的问题，就直接使用`torch.lstsq()`。对于不能用`torch.lstsq()`解决的情况（如损失不是MSE损失，或数据太多而没有办法一下子全载入内存)，才考虑用**优化算法来求解权值**。

### 理论基础2：torch.nn.Linear
`torch.nn`子包里的`torch.nn.Module`扩展类不仅有很多损失类，还有`torch.nn.Linear`类。

在构造`torch.nn.Linear`类实例时，需提供两个int型参数。这两个参数原意是表示**每个神经元有几个输入**，以及**每层有多少个神经元**。在线性回归的语义下，这两个参数就相当于**特征的个数**和**因变量的个数**。除了这两个参数外，还有一个关键字参数`bias`，表示是否使用偏移：
- `bias=True`(默认)：考虑偏移，线性模型为 $y = x[0]w[0] + x[1]w[1] + ... + x[m-1]w[m-1] + w[m]$
- `bias=False`：不考虑偏移，线性模型为 $y = x[0]w[0] + x[1]w[1] + ... + x[m-1]w[m-1]$

`torch.nn.Linear`类的实例对象还有一个成员方法`parameters()`，它返回一个张量的生成器（generator），可以生成这个模块涉及的所有可求导的张量。要从生成器得到生成的结果，可以用Python3的内置函数`next()`。每调用一次`next()`函数，可以得到一个值。`torch.nn.Linear`类的实例对象在`bias=True`的情况下，`parameters()`返回的生成器可以生成一个大小为`(特征的个数，因变量的个数)`的**权重张量**和大小为`(因变量个数，)`的**偏移张量**。通过这两个张量的值，可以知道回归的结果。

### 代码实现2
```python
import torch
import torch.nn
import torch.optim

x = torch.tensor([[1., 1.], [2., 3.], [3., 5.], [4., 2.], [5., 4.]])
y = torch.tensor([-10., 12., 14., 16., 18.]).reshape(-1, 1)

fc = torch.nn.Linear(2, 1)
criterion = torch.nn.MSELoss()
optimizer = torch.optim.Adam(fc.parameters())
weights, bias = fc.parameters()

for step in range(30001):
    if step:
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    pred = fc(x)
    loss = criterion(pred, y)
    if step % 1000 == 0:
        print('step = {}, loss = {:g}, weights = {}, bias = {}'.format(step, loss, weights[0, :].tolist(), bias.item()))
```

> 说明：无需再显式定义权重张量W，而是构造了`torch.nn.Linear`类的实例对象。这个实例中就包括了我们关心的权重张量。而且对于这里的特征张量不需要再补齐没有实际意义的1，因为使用了`torch.nn.Linear`类并对偏移进行了特殊处理。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210428145023867.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5X3oxMTEyMQ==,size_16,color_FFFFFF,t_70)
## 数据的归一化
### 理论基础
对数据进行归一化，*使得优化器面对的每个特征的数值或标签的数值在一个相对固定的范围内*，这样就能使损失下降的更快。归一化得到的特征或标签的均值为0，方差为1。这样，它们的取值范围就相对固定了。

适合对数据进行归一化的情况：特征的数值范围和标签的数值范围差别很大时；不同特征值之间的数值范围查别很大时。

如何进行数据归一化？`torch.mean()`函数和`torch.std()`函数可以用于求解张量的均值和方差。利用这两个函数我们可以将某个特征或标签A归一化为：$A' = \frac{A-mean(A)}{std(A)}$.

### 代码实现
在没有数据归一化的情况下进行线性回归：
```python
import torch.nn
import torch.optim


x = torch.tensor([[1000000, 0.0001], [2000000, 0.0003], [3000000, 0.0005], [4000000, 0.0002], [5000000, 0.0004]])
y = torch.tensor([-1000., 1200., 1400., 1600., 1800.]).reshape(-1, 1)

fc = torch.nn.Linear(2, 1)
criterion = torch.nn.MSELoss()
optimizer = torch.optim.Adam(fc.parameters())


for step in range(30001):
    if step:
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    pred = fc(x)
    loss = criterion(pred, y)
    if step % 1000 == 0:
        print('step = {}, loss = {:g}'.format(step, loss))
```
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210428150337984.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5X3oxMTEyMQ==,size_16,color_FFFFFF,t_70)

借助数据归一化进行线性回归：
```python
import torch
import torch.nn
import torch.optim


x = torch.tensor([[1000000, 0.0001], [2000000, 0.0003], [3000000, 0.0005], [4000000, 0.0002], [5000000, 0.0004]])
y = torch.tensor([-1000., 1200., 1400., 1600., 1800.]).reshape(-1, 1)

x_mean, x_std = torch.mean(x, dim=0), torch.std(x, dim=0)
x_norm = (x - x_mean) / x_std
y_mean, y_std = torch.mean(y, dim=0), torch.std(y, dim=0)
y_norm = (y - y_mean) / y_std

fc = torch.nn.Linear(2, 1)
criterion = torch.nn.MSELoss()
optimizer = torch.optim.Adam(fc.parameters())


for step in range(30001):
    if step:
        optimizer.zero_grad()
        loss_norm.backward()
        optimizer.step()

    pred_norm = fc(x_norm)
    loss_norm = criterion(pred_norm, y_norm)
    pred = pred_norm * y_std + y_mean
    loss = criterion(pred, y)
    if step % 1000 == 0:
        print('step = {}, loss = {:g}'.format(step, loss))
```
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210428151555727.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5X3oxMTEyMQ==,size_16,color_FFFFFF,t_70)

对比两程序的输出结果可知，*归一化后损失下降得更快*。

# 分类问题（线性判决与逻辑回归）
## 用优化器实现逻辑回归
在PyTorch中，损失类`torch.nn.BCELoss`和损失类`torch.nn.BCEWithLogitsLoss`实现了**互熵损失**。这两个类的区别在于使用损失类实例时，`BCELoss`类实例需要的参数是预测概率张量P和标签张量Y，而`BCEWithLogitsLoss`类实例需要的参数是对数赔率张量Z和标签张量Y。`BCEWithLogitsLoss`类实例得到对数赔率张量Z后，会将逐元素的`expit()`运算和互熵损失的运算结合起来，使得运算更加稳健高效。因此，在**二项逻辑回归**（指的是标签只有0、1两个类型）中一般只用`BCEWithLogitsLoss`类。

下面使用`BCEWithLogitsLoss`类实现逻辑回归，调用该类实例得到损失值，再利用优化器最小化损失，得到权重的最优值。	
```python
import torch
import torch.nn
import torch.optim

x = torch.tensor([[1., 1., 1.], [2., 3., 1.], [3., 5., 1.], [4., 2., 1.], [5., 4., 1.]])
y = torch.tensor([0., 1., 1., 0., 1.])
w = torch.zeros(3, requires_grad=True)

criterion = torch.nn.BCEWithLogitsLoss()
optimizer = torch.optim.Adam([w, ], )

for step in range(100001):
    if step:
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    pred = torch.mv(x, w)
    loss = criterion(pred, y)
    if step % 10000 == 0:
        print('第{}步：loss = {:g}, W = {}'.format(step, loss, w.tolist()))
```
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210428173821684.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5X3oxMTEyMQ==,size_16,color_FFFFFF,t_70)
## 多项逻辑回归
多项逻辑回归指的是分类结果不只2种的分类问题。

涉及到的PyTorch中的函数：`softmax()`——`expit()`的一种扩展形式、`torch.nn.CrossEntropyLoss`——互熵损失。
> 在调用`torch.nn.CrossEntropyLoss`类的实例对象时，要依次传入可以求梯度的特征张量和不能求导数的标签张量。注意，标签张量的数据类型必须是整型的，这可以在构造张量时将`torch.Tensor`类换成`torch.LongTensor`类来实现。

下面使用`torch.nn.CrossEntropyLoss`损失解决多标签值的回归问题。
```python
import torch
import torch.nn
import torch.optim

x = torch.tensor([[1., 1., 1.], [2., 3., 1.], [3., 5., 1.], [4., 2., 1.], [5., 4., 1.]])
y = torch.tensor([0, 2, 1, 0, 2])  # 分类结果有0,1,2三种
w = torch.zeros(3, 3, requires_grad=True)  # 注意权重张量的维数（与分类钟数有关联，不同类别对应了不同的权重）

criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam([w, ], )

for step in range(100001):
    if step:
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    pred = torch.mm(x, w)
    loss = criterion(pred, y)
    if step % 10000 == 0:
        print('第{}步：loss = {:g}, W = {}'.format(step, loss, w))
```
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210428180044847.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5X3oxMTEyMQ==,size_16,color_FFFFFF,t_70)
## 实例：利用多项逻辑回归识别手写数字
- 利用逻辑回归得到一个线性判决器，解决MNIST图片库的数字识别问题。
- 每条数据的特征是28*28个[0,1]之间的实数，它代表一张灰度图像。每条数据的标签是0~9这10个自然数中的任意一个，代表图片上显示的数字。MNIST问题含有训练集和测试集，训练集里有6万张图片，测试集里有1万张图片。
```python
import torch
import torch.nn
import torch.optim
import torchvision
from torchvision import datasets, transforms
from torchvision.transforms import ToTensor


# Step1. 数据集下载
transform = transforms.Compose([transforms.ToTensor()])

data_train = datasets.MNIST(
    root="./dataMNIST/",
    transform=transform,
    train=True,
    download=True
)

data_test = datasets.MNIST(
    root='./dataMNIST/',
    train=False,
    transform=transform
)


# Step2. 数据装载
data_loader_train = torch.utils.data.DataLoader(dataset=data_train, batch_size=64, shuffle=True)
print(f'len(data_loader_train) = {len(data_loader_train)}')
data_loader_test = torch.utils.data.DataLoader(dataset=data_test, batch_size=64, shuffle=True)
print(f'len(data_loader_test) = {len(data_loader_test)}')


# Step3. 利用多项逻辑回归识别MNIST数据
# 3.1 训练线性判决器
fc = torch.nn.Linear(28*28, 10)   # 该语句就定义了权重张量
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(fc.parameters())

num_epochs = 5
for epoch in range(num_epochs):
    for idx, (images, labels) in enumerate(data_loader_train):  # 对一批数据做出预测
        x = images.reshape(-1, 28*28)
        optimizer.zero_grad()
        preds = fc(x)  # 直接使用fc实例对象为未知数据做判决
        loss = criterion(preds, labels)
        loss.backward()
        optimizer.step()

        if idx % 100 == 0:
            print('第{}趟第{}批：loss = {:g}'.format(epoch, idx, loss))

# 3.2 对训练好的线性判决器进行测试
correct = 0
total = 0
for images, labels in data_loader_test:
    x = images.reshape(-1, 28*28)
    preds = fc(x)
    predicted = torch.argmax(preds, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()
accuracy = correct / total
print('测试集上的准确率：{:.1%}'.format(accuracy))
```
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210428185906366.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5X3oxMTEyMQ==,size_16,color_FFFFFF,t_70)
## 实例：股票趋势预测
```python
'''
需求：
    读取股票每日价格和成交量数据，并利用线性判决预测未来成交量是否会增加。
步骤：
    1. 使用扩展库pandas-datareader包从Quandl数据库读取美股的价格和成交量数据。
        使用pandas-datareader包下data子包的DataReader(股票名称，数据源的名称，数据的开始日期，数据的结束日期，quandl官网注册后获得的api_key)函数读入数据
            Quandl是为投资专业人士提供财务、经济和替代数据的平台
            DataReader()函数的返回值是pandas.DataFrame类的实例，这个类可以用来表示二维表格。
    2. 取得特征和标签
    3. 训练和测试线性判决器
'''
from pandas_datareader.data import DataReader
import torch
import torch.nn
import torch.optim


df = DataReader('FB.US', 'quandl', '2012-01-01', '2018-02-01', api_key="DNExoMS7zYCE7As7LsXU")
print(df)


# 训练集：从2013年到2017的数据，共1008个交易日，其中，471个交易日的次日成交量与当日成交量相比有增加，另外537个交易日没有增加
train_start, train_end = sum(df.index >= '2017'), sum(df.index >= '2013')
n_total_train = train_end - train_start
# 测试集：2017年的数据，共250个交易日，其中，114个有增加，136个无增加。
test_start, test_end = sum(df.index >= '2018'), sum(df.index >= '2017')
n_total_test = test_end - test_start
# 将特征用训练集中的均值和方差进行归一化
s_mean = df[train_start:train_end].mean()
s_std = df[train_start:train_end].std()
n_features = 5
df_feature = ((df - s_mean) / s_std).iloc[:, :n_features]       # 特征
s_label = (df['Volume'] < df['Volume'].shift(1)).astype(int)    # 标签


fc = torch.nn.Linear(n_features, 1)
weights, bias = fc.parameters()
criterion = torch.nn.BCEWithLogitsLoss()
optimizer = torch.optim.Adam(fc.parameters())

x = torch.tensor(df_feature.values, dtype=torch.float32)
y = torch.tensor(s_label.values.reshape(-1, 1), dtype=torch.float32)

n_step = 20001
for step in range(n_step):   # 因为数据不多所以直接一批下来做预测，然后循环多次即可
    if step:
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    pred = fc(x)
    loss = criterion(pred[train_start:train_end], y[train_start:train_end])

    if step % 500 == 0:
        print('#{}, 损失 = {:g}, '.format(step, loss))

        output = (pred > 0)
        correct = (output == y.byte())      # ???
        n_correct_train = correct[train_start:train_end].sum().item()
        n_correct_test = correct[test_start:test_end].sum().item()
        accuracy_train = n_correct_train / n_total_train
        accuracy_test = n_correct_test / n_total_test
        print('训练集准确率 = {}， 测试集准确率 = {}'.format(accuracy_train, accuracy_test))
```
# 全连接神经网络
## 前馈神经网络
### 使用torch.nn.Sequential类搭建FFNN

> 前馈神经网络（Feed-Forward Neutral Network, FFNN）.

- `torch.nn.Sequential`类是由`torch.nn.Module`类派生得到的。可以使用`torch.nn.Sequential`类搭建FFNN，还可以通过扩展`torch.nn.Module`类来搭建神经网络。
- `torch.nn.Module`类及其子类有以下用途：
	- 表示一个神经网络。例如，`torch.nn.Sequential`类可以表示一个前馈神经网络。
	- 表示神经网络的一个层。例如，前面学习过的`torch.nn.Linear`类就是表示神经网络的一个层的线性连接部分，它是一种线性层；`torch.nn.ReLU`类表示逐元素计算`max(·, 0)`，它是一种激活层。
	- 表示损失。例如，前面学习过的`torch.nn.MSELoss`类、`torch.nn.L1Loss`类、`torch.nn.SmoothL1Loss`类、`torch.nn.BCEWithLogitsLoss`类、`torch.nn.CrossEntropyLoss`类。

> PyTorch让`torch.nn.Module`类同时服务于这三种功能，是因为无论是神经网络、一个层或是损失都可能自带需要优化的参数。如果用同样的接口来表示，可以统一用法、简化编程。比如可以使用类实例的成员方法`parameters()`获得变量，或是用类实例的成员方法`zero_grad()`清除变量的梯度值。

- 由于FFNN就是将一些层依次连接起来，所以使用类`torch.nn.Sequential`，也就是将对应的表示层的类依次传给`torch.nn.Sequential`类实例的构造方法。

```python
from torch.nn import Linear, ReLU, Sequential
net = Sequential(Linear(4, 2),
                 ReLU(),
                 Linear(2, 1),
                 ReLU())
print(net)

'''
类实例net表示的神经网络依次为：
    有4个输入、2个输出的线性组合；
    对数据做max(·, 0)运算；
    有2个输入、1个输出的线性组合；
    对数据做max(·, 0)运算。
'''
```
## 非线性激活
- `torch.nn`子包里实现了很多激活层。
### 逐元素激活
根据非线性运算图像的形状，可以将用于逐元素激活的激活层分为以下三类：
- S(Sigmoid)形激活
	- `torch.nn.Softsign`
	-  `torch.nn.Sigmoid`
	- `torch.nn.Tanh`
	- `torch.nn.Hardtanh`
	- `torch.nn.ReLU6`
- 单侧激活
	- `torch.nn.ReLU`
	- `torch.nn.LeakyReLU`
	- `torch.nn.RReLU`
	- `torch.nn.PReLU`
	- `torch.nn.Threshold`
	- `torch.nn.ELU`
	- `torch.nn.SELU`
	- `torch.nn.Softplus`
	- `torch.nn.LogSigmoid`
- 皱缩激活
	- `torch.nn.Hardshrinkage`
	- `torch.nn.Softshrinkage`
	- `torch.nn.Tanhshrinkage`
> 这3大类的激活函数各有利弊。在选择激活函数时，最常见的考量是输出的范围和梯度是否消失。如果不知道应该选什么激活函数，不妨先试试`torch.nn.Sigmoid`类，再试试`torch.nn.LeakyReLU`类。

### 非逐元素激活
> 非逐元素激活相当于进行了多值判决，从多个特征中选择了一个特征。这一功能是常见逐元素激活不方便实现的。
> `torch.nn.Softmax`
> `torch.nn.Softmax2d`
> `torch.nn.LogSoftmax`
## 实例：基于全连接网络的非线性回归
生成一些示例数据，并将这些数据分割为**训练集**、**验证集**和**测试集**，再根据训练集和验证集选择网络结构，利用训练集训练网络，利用测试集数据测试训练得到的网络的性能。
```python
import torch
import torch.nn as nn

# 1. 利用Himmelblau函数生成有噪数据
torch.manual_seed(seed=0)  # 固定随机数种子，这样生成的数据是确定的
sample_num = 1000          # 生成1000条数据
features = torch.rand(sample_num, 2) * 12 - 6  # 特征数据
noises = torch.randn(sample_num)
def himmelblau(x):
    return (x[:, 0] ** 2 + x[:, 1] - 11) ** 2 + (x[:, 0] + x[:, 1] ** 2 - 7) ** 2
hims = himmelblau(features) * 0.01
labels = hims + noises     # 标签数据


# 2. 将数据分隔为训练集、验证集和测试集，查看各数据集上的噪声大小
train_num, validate_num, test_num = 600, 200, 200  # 通常按照60%、20%、20%的比例
train_mse = (noises[:train_num] ** 2).mean()
validate_mse = (noises[train_num:-test_num] ** 2).mean()
test_mse = (noises[-test_num:] ** 2).mean()
print('真实：训练集MSE = {:g}, 验证集MSE = {:g}, 测试集MSE = {:g}'.format(train_mse, validate_mse, test_mse))


# 3. 使用偏差方差分析确定网络的结构（选择某个网络结构，绘制学习曲线和验证曲线，再通过减小网络或增大网络来判断是否出现欠拟合或过拟合）
'''
作为开始，我们考虑3层神经网络，前两个隐含层分别有6个神经元和2个神经元，并使用逻辑函数激活；
最后一层输出层有1个神经元，没有非线性激活。
将torch.nn.Sequential类的构造参数放在一个列表里。这样做是为了让后续的代码可以轻易的修改神经网络的层数和每层的神经元的个数。
'''
hidden_features = [6, 2]  # 表示共2个隐含层，每层的神经元个数分别为6、2
layers = [nn.Linear(2, hidden_features[0]), ]
for idx, hidden_feature in enumerate(hidden_features):
    layers.append(nn.Sigmoid())
    next_hidden_feature = hidden_features[idx + 1] \
        if idx + 1 < len(hidden_features) else 1
    layers.append(nn.Linear(hidden_feature, next_hidden_feature))
net = nn.Sequential(*layers)
# print('神经网络为{}'.format(net))


# 4. 计算特定结构的神经网络在某训练数据条目下的训练差错和验证差错
import torch.optim
optimizer = torch.optim.Adam(net.parameters())
criterion = nn.MSELoss()

train_entry_num = 600  # 选择训练样本数(可修改为100,200,400，得到不同训练数据条目数的情况下的差错值)

n_iter = 100000
for step in range(n_iter):
    outputs = net(features)
    preds = outputs.squeeze()

    loss_train = criterion(preds[:train_entry_num], labels[:train_entry_num])
    loss_validate = criterion(preds[train_num:-test_num], labels[train_num:-test_num])
    if step % 10000 == 0:
        print('#{} 训练集MSE = {:g}, 验证集MSE = {:g}'.format(step, loss_train, loss_validate))

    optimizer.zero_grad()
    loss_train.backward()
    optimizer.step()

print('训练集MSE = {:g}, 验证集MSE = {:g}'.format(loss_train, loss_validate))


# 5. 试图增加或减小网络的复杂度...


# 6. 计算测试集上的差错
outputs = net(features)
preds = outputs.squeeze()
loss = criterion(preds[-test_num:], labels[-test_num:])
print(loss)
```
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210430122058320.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5X3oxMTEyMQ==,size_16,color_FFFFFF,t_70)

# 卷积神经网络
## 卷积层
卷积神经网络（Convolutional Neural Networks，CNN）在*计算机视觉* 方面贡献颇丰。

卷积神经网络的核心是互相关（cross-correlation）运算和卷积（convolution）运算。互相关运算和卷积运算都是二元运算，它们都可以将两个序列映射为一个新的序列。

`torch.nn`包里的卷积层负责完成互相关运算和卷积运算，所有这些层都是`torch.nn.Module`类的子类。具体如下：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210429200934545.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5X3oxMTEyMQ==,size_16,color_FFFFFF,t_70)

- n维互相关对应的层为`torch.nn.Conv[n]d`类。构造类的实例时，参数依次为：
  `in_channels` 输入通道数
  `out_channels` 输出通道数
  `kernel_size` 核大小
  `stride` 步幅（默认为1）
  `padding` 补全（默认为0）
  `dilation` 膨胀系数（默认为1）
  `groups`  通道之间运算的分组（默认为1）
  `bias` 是否有偏差项（默认为有）

- n维转置卷积对应的层为`torch.nn.ConvTranspose[n]d`类。构造类的实例时，参数依次为：
  `in_channels` 输入通道数
  `out_channels` 输出通道数
  `kernel_size` 核大小
  `stride` 步幅（默认为1）
  `padding` 补全（默认为0）
  `output padding` 输出补全（默认为0）
  `dilation` 膨胀系数（默认为1）
  `groups`  通道之间运算的分组（默认为1）
  `bias` 是否有偏差项（默认为有）

示例：
```python
import torch

conv = torch.nn.Conv2d(16, 33, kernel_size=(3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))
inputs = torch.randn(20, 16, 50, 100)
outputs = conv(inputs)
print(outputs.size())
```

在图像处理等问题中常常使用卷积层。这是因为，互相关运算和转置卷积运算可以**提取出图像的特征**。互相关运算和转置卷积运算都是对输入的元素做线性组合，但是它与全连接层相比，权重的数量少很多。而且，对于某种类型的特征，无论它出现在图片中的哪个部分，都会由相同的卷积核得出相同的结果。因此，**只要用很少的权重值就有能力抽取图片中的特征**。如果把卷积层换成全连接层，则会造成参数过多，一方面训练困难，另一方面容易出现过拟合。**因此，在图片和视频等媒体的处理中，往往会用卷积层抽取图像特征。**获得图像特征后，再使用全连接层等根据图像特征做后续的判别等运算。

## 池化层、视觉层、补全层
与互相关运算和转置卷积运算具有直接关系的运算：池化运算、反池化运算和补全运算，以及与反池化相似的上采样运算。PyTorch中实现这些运算的是池化层（池化运算、反池化运算）、视觉层（上采样运算）和补全层（补全运算）。

`torch.nn`子包里的池化层：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210430132318604.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5X3oxMTEyMQ==,size_16,color_FFFFFF,t_70)
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210430132343859.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5X3oxMTEyMQ==,size_16,color_FFFFFF,t_70)

`torch.nn`子包里的视觉层：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210430132407846.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5X3oxMTEyMQ==,size_16,color_FFFFFF,t_70)
> `mode`的参数值可以是`nearest`、`linear`、`bilinear`、`trilinear`，分别表示最近邻上采样、一维线性上采样、二维线性上采样、三维线性上采样。


`torch.nn`子包里的补全层：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210430132436847.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5X3oxMTEyMQ==,size_16,color_FFFFFF,t_70)
## 实例：MNIST图片分类的改进
搭建*卷积神经网络* 来完成MNIST判决问题，这比线性判决器更加强大也更加复杂，可以得到更好的性能。

部分：

```python
'''
一般情况下，用于图像处理的卷积神经网络可以分为两个部分：
    1. 第一部分提取特征——由卷积层完成
    2. 第二部分利用提取的特征——
        1）首先会进行池化来避免相同特征的简单重复
        2）然后利用全连接层和ReLU层(或类似的激活层)对特征进行运算得到目标结果
        3）在全连接层前后，还可以安插丢弃层，其作用是在输入张量中随机选择一部分元素令其为0(即“丢弃”)，剩下的元素保持不变。同一丢弃层在不同次使用时会随机选择不同的元素丢弃。引入丢弃可以防止过拟合，所以丢弃层在输入大小较大或输出大小较大的全连接层前。
'''

import torch.nn

class Net(torch.nn.Module):
    '''
    前4层用于特征提取:
        前一个卷积层将1个通道(即图像的灰度通道)映射到64个通道(即支持至多64种不同的小局部特征)；
        后一个卷积层将64个通道映射到128个通道(即支持至多128种不同的稍大的局部特征)。
    在之后的特征利用部分：
        首先用最大池化削减分辨率，使得每个通道的大小减小为(14, 14)。这样，每条数据就变成大小为(128, 14, 14)的特征张量。
        接下来使用一个全连接层进行数字的判定。但首先要把大小为(128, 14, 14)的特征张量重排为大小为(128*14*14,)的一维张量。
        ReLU激活层之后，考虑到1024这个数比较大，所以网络还安排了一个丢弃层，丢弃概率为默认值0.5.
        最后还有一个全连接层。
    '''
    def __init__(self):
        super(Net, self).__init__()
        self.conv0 = torch.nn.Conv2d(1, 64, kernel_size=3, padding=1)
        self.relu1 = torch.nn.ReLU()
        self.conv2 = torch.nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.relu3 = torch.nn.ReLU()
        self.pool4 = torch.nn.MaxPool2d(stride=2, kernel_size=2)
        self.fc5 = torch.nn.Linear(128 * 14 * 14, 1024)
        self.relu6 = torch.nn.ReLU()
        self.drop7 = torch.nn.Dropout(p=0.5)
        self.fc8 = torch.nn.Linear(1024, 10)

    def forward(self, x):
        x = self.conv0(x)
        x = self.relu1(x)
        x = self.conv2(x)
        x = self.relu3(x)
        x = self.pool4(x)
        x = x.view(-1, 128*14*14)
        x = self.fc5(x)
        x = self.relu6(x)
        x = self.drop7(x)
        x = self.fc8(x)
        return x
    
net = Net()
```

完整：

```python
import torch
import torch.nn
import torch.optim
import torchvision
from torchvision import datasets, transforms
from torchvision.transforms import ToTensor


# Step1. 数据集下载
transform = transforms.Compose([transforms.ToTensor()])

data_train = datasets.MNIST(
    root="./dataMNIST/",
    transform=transform,
    train=True,
    download=True
)

data_test = datasets.MNIST(
    root='./dataMNIST/',
    train=False,
    transform=transform
)


# Step2. 数据装载
data_loader_train = torch.utils.data.DataLoader(dataset=data_train, batch_size=64, shuffle=True)
print(f'len(data_loader_train) = {len(data_loader_train)}')
data_loader_test = torch.utils.data.DataLoader(dataset=data_test, batch_size=64, shuffle=True)
print(f'len(data_loader_test) = {len(data_loader_test)}')


# Step3. 搭建网络结构
class Net(torch.nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = torch.nn.Sequential(
            torch.nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),  # 卷积层
            torch.nn.ReLU(),                                             # 激活层
            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),# 卷积层
            torch.nn.ReLU(),                                             # 激活层
            torch.nn.MaxPool2d(stride=2, kernel_size=2)                  # 最大池化层
        )
        self.dense = torch.nn.Sequential(         # 定义全连接层
            torch.nn.Linear(14*14*128, 1024),
            torch.nn.ReLU(),
            torch.nn.Dropout(p=0.5),              # 防止卷积神经网络在训练的过程中发生过拟合
            torch.nn.Linear(1024, 10)
        )

    def forward(self, x):           # 前向传播
        x = self.conv1(x)           # 进行卷积处理
        x = x.view(-1, 14*14*128)   # 对参数实现扁平化(如果不进行扁平化，则之后的全连接层进行分类时会使得实际输出的参数维度和其定义输入的维度不匹配)
        x = self.dense(x)           # 调用全连接层进行分类
        return x


# Step4. 训练
net = Net()
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(net.parameters())

num_epochs = 5
for epoch in range(num_epochs):
    for idx, (images, labels) in enumerate(data_loader_train):  # 每次均是对一批数据做出预测
        optimizer.zero_grad()
        preds = net(images)  # 直接使用fc实例对象为未知数据做判决
        loss = criterion(preds, labels)
        loss.backward()
        optimizer.step()

        if idx % 100 == 0:
            print('第{}趟第{}批：loss = {:g}'.format(epoch, idx, loss.item()))

# Step5. 测试
correct = 0
total = 0
for images, labels in data_loader_test:
    preds = net(images)
    predicted = torch.argmax(preds, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()
accuracy = correct / total
print('测试集上的准确率：{:.1%}'.format(accuracy))
```

-- --
一个标准的CNN架构主要由卷积层、池化层和全连接层等核心层次构成。
- 卷积层  Convolutional Layers：对输入的数据进行**特征提取**
- 池化层 Polling Layers：提取输入数据的核心特征，实现了对原始数据的压缩，大量减少了参与模型计算的参数，提升了计算效率。
	- 平均池化层 average pooling
	- 最大池化层 max pooling
-  全连接层 Fully Connected Layer：将输入图像在经过卷积和池化操作后提取的特征进行压缩，并且根据压缩的特征完成模型的分类功能。


# 循环神经网络
- 常见的循环单元有3种：基本循环神经元、长短期记忆单元、门控循环单元。
PyTorch中RNN的实现类见下图：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210430190411238.png)
> 上图中所有类都是`torch.nn.Module`类的子类。
## 循环单元类
构造`torch.nn.RNNCell`, `torch.nn.LSTMCell`, `torch.nn.GRUCell`实例时，需传入的参数：
- `input_size`：int类型，表示输入大小。
- `hidden_size`：int类型，表示隐藏大小。
- `bias`：bool类型，表示是否需要引入偏差张量。默认为True。

注意，对于`torch.nn.GRUCell`类，还有一个额外的参数`nonlinearity`，表示线性变换后的输出使用何种函数激活。默认值为tanh，表示使用tanh()函数激活。

构造的类实例自带4个或2个可以训练的变量。如果参数`bias`为True，则有四个变量；否则，只有两个变量：
![在这里插入图片描述](https://img-blog.csdnimg.cn/2021043019031771.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5X3oxMTEyMQ==,size_16,color_FFFFFF,t_70)
示例：构造RNNCell类实例并查看变量内容
```python
import torch.nn

cell = torch.nn.RNNCell(input_size=3, hidden_size=5)
for name, param in cell.named_parameters():
    print('{} = {}'.format(name, param))
```
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210430190645971.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5X3oxMTEyMQ==,size_16,color_FFFFFF,t_70)
示例：构造LSTMCell类实例并用其搭建单向单层循环神经网络
```python
import torch

seq_len, batch_size = 6, 2
input_size, hidden_size = 3, 5
cell = torch.nn.LSTMCell(input_size=input_size, hidden_size=hidden_size)
inputs = torch.randn(seq_len, batch_size, input_size)
h = torch.randn(batch_size, hidden_size)
c = torch.randn(batch_size, hidden_size)
hs = []
for t in range(seq_len):
    h, c = cell(inputs[t], (h, c))
    hs.append(h)
outputs = torch.stack(hs)
print(outputs)
```
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210430192818747.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5X3oxMTEyMQ==,size_16,color_FFFFFF,t_70)
## 循环神经网络类
因为如果是自己连接循环单元的输入输出会比较麻烦，所以我们最好使用`torch.nn`子包里提供给我们的连好的循环神经网络。

构造`torch.nn.RNN`, `torch.nn.LSTM`, `torch.nn.GRU`实例时，除了能够传入与其对应的循环单元类构造时的参数外，还有可选参数：
- num_layers：int型，表示循环神经网络的层数。默认值为1，，表示单层神经网路。对于双向循环神经网络，这个值表示每个方向各有几层。
- batch_first：bool型，默认值为False。
- dropout：数值类型，默认为0. 对于多层神经网络，表示各层之间随机丢弃的概率。默认值0表示无丢弃操作。
- bidirectional：bool类型。默认值为False，表示单向循环结构；若该参数为True表示双向循环结构。

```python
import torch
import torch.nn

num_layers = 2
seq_len, batch_size = 6, 2
input_size, hidden_size = 3, 5
rnn = torch.nn.GRU(input_size, hidden_size, num_layers=num_layers)
inputs = torch.randn(seq_len, batch_size, input_size)
h0 = torch.randn(num_layers, batch_size, hidden_size)
outputs, hn = rnn(inputs, h0)
print(outputs)
```
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210430202139682.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5X3oxMTEyMQ==,size_16,color_FFFFFF,t_70)
## 实例：人均GDP的预测
```python
from pandas_datareader import wb
import torch.nn
import torch
import torch.optim


# 1. 从世界银行获取各国历年GDP数据
countries = ['BR', 'CA', 'CN', 'FR', 'DE', 'IN', 'IL', 'JP', 'SA', 'GB', 'US',]
dat = wb.download(indicator='NY.GDP.PCAP.KD', country=countries, start=1970, end=2016)
df = dat.unstack().T
df.index = df.index.droplevel(0)

# 2. 神经网络的搭建
'''
    人均GDP是时间序列，尤其适合使用循环神经网络进行预测。
'''
class Net(torch.nn.Module):
    def __init__(self, input_size, hidden_size):
        super(Net, self).__init__()
        self.rnn = torch.nn.LSTM(input_size, hidden_size)
        self.fc = torch.nn.Linear(hidden_size, 1)

    def forward(self, x):
        x = x[:, :, None]  # 将变量x的大小从(n, m)变为(n, m, 1), 这样才适应循环神经网络
        x. _ = self.rnn(x)
        x = self.fc(x)
        x = x[:, :, 0]     # 全连接层后，又将x的大小从(n, m, 1)变为(n, m)
        return x

net = Net(input_size=1, hidden_size=5)
print(net)

# 3. 数据归一化
df_scaled = df / df.loc[2000]


# 4. 确定训练集和测试集
years = df.index
train_seq_len = sum((years >= 1971) & (years <= 2000))
test_seq_len = sum(years > 2000)
print(f'训练集长度 = {train_seq_len}， 测试集长度 = {test_seq_len}')


# 5. 确定训练使用的特征和标签
inputs = torch.tensor(df_scaled.iloc[:-1].values, dtype=torch.float32)
labels = torch.tensor(df_scaled.iloc[1:].values, dtype=torch.float32)


# 6. 训练网络
criterion = torch.nn.MSELoss()
optimizer = torch.optim.Adam(net.parameters())
for step in range(10001):
    if step:
        optimizer.zero_grad()
        train_loss.backward()
        optimizer.step()

    preds = net(inputs)
    train_preds = preds[:train_seq_len]
    train_labels = labels[:train_seq_len]
    train_loss = criterion(train_preds, train_labels)

    test_preds = preds[-test_seq_len]
    test_labels = labels[-test_seq_len]
    test_loss = criterion(test_preds, test_labels)

    if step % 500 == 0:
        print(f'第{step}次迭代：loss(训练集) = {train_loss}, loss(训练集) = {test_loss}')


# 7. 使用训练好的网络做预测
from IPython.display import display
preds = net(inputs)
df_pred_scaled = pd.DataFrame(preds.detach().numpy(),
                              index=years[1:], columns=df.columns)
df_pred = df_pred_scaled * df.loc[2000]
display(df_pred.loc[2001:])
```
# 生成对抗网络
## 介绍
生成对抗网络（Generative Adversarial Network，GAN）可以基于现有的数据生成类似的新数据。GAN是一种非监督学习，已有的真实数据没有什么特别的标签。GAN引入了一个鉴别网络，来鉴别生成的假数据和真实数据。鉴别网络的判断可以指导GAN如何生成假数据。   

生成对抗网络主要包括生成网络和鉴别网络，它们可以是任何类型的神经网络，如全连接神经网络、卷积神经网络、循环神经网络等。

深度卷积生成对抗网络（Deep Convolution GAN，DCGAN）对生成网络和鉴别网络做出了重要的改进和约束，可以生成更大的彩色图片。DCGAN需要进行规范化操作。PyTorch子包里实现规范化运算的类：

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210502133842249.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5X3oxMTEyMQ==,size_16,color_FFFFFF,t_70)

构造以上类实例时，需要提供以下参数：
`num_features`：int型，表示特征个数，即输入输出张量第1维大小c。
`eps`：浮点型。
`momentum`：动量，有助于均值和方差保持稳定，默认值为0.1。
`affine`：bool型。默认为True，表示需要引入可训练的放缩和平移参数。否则，不进行额外的放缩和平移。

## 网络权重的初始化
合适的对网络的权重进行初始化，可以使得网络的训练更加容易。

在PyTorch里完成权重初始化需要借助`torch.nn.init`子包和`torch.nn.Module`类的成员方法`apply()`。

- `torch.nn.init`子包里定义了许多函数，这些函数可以改变张量的值。常用函数：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20210502140351526.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2p5X3oxMTEyMQ==,size_16,color_FFFFFF,t_70)
一般情况下，对于线性层和卷积层，将权重张量中的元素按均匀分布或正态分布初始化，将偏差张量中的元素初始化为0。
- `torch.nn.init`子包里的`torch.nn.init.calculate_gain()`函数可以帮助我们计算得到各种激活层对应的增益值。
- `torch.nn.Module`类的成员方法`apply()`有一个参数，这个参数是一个Python函数，这个函数的参数必须是`torch.nn.Module`类。当调用`apply()`时`torch.nn.Module`类及其内部的`torch.nn.Module`类实例会递归的调用传入的函数。

```python
from torch.utils.data import DataLoader
from torchvision.datasets import CIFAR10
import torchvision.transforms as transforms
from torchvision.utils import save_image
import torch.nn as nn
import torch.nn.init as init


dataset = CIFAR10(root='./dataCIFAR',
                  download=True,
                  transform=transforms.ToTensor())
dataloader = DataLoader(dataset, batch_size=64, shuffle=True)


# 将部分批次保存为图片文件
# for batch_idx, data in enumerate(dataloader):
#     real_images, _ = data
#     batch_size = real_images.size(0)
#     print('#{} has {} images.'.format(batch_idx, batch_size))
#     if batch_idx % 100 == 0:
#         path = './dataCIFAR/CIFAR10_shuffled_batch{:03d}.png'.format(batch_idx)
#         save_image(real_images, path, normalize=True)


# 搭建生成网络
latent_size = 64  # 潜在大小
n_channel = 3     # 输出通道数
n_g_feature = 64  # 生成网络隐藏层大小
gnet = nn.Sequential(
    # 输入大小 = (64, 1, 1)
    nn.ConvTranspose2d(latent_size, 4*n_g_feature, kernel_size=4, bias=False),
    nn.BatchNorm2d(4 * n_g_feature),
    nn.ReLU(),
    # 大小 = (256, 4, 4)
    nn.ConvTranspose2d(4 * n_g_feature, 2 * n_g_feature, kernel_size=4, stride=2, padding=1, bias=False),
    nn.BatchNorm2d(2 * n_g_feature),
    nn.ReLU(),
    # 大小 = (128, 8, 8)
    nn.ConvTranspose2d(2 * n_g_feature, 2 * n_g_feature, kernel_size=4, stride=2, padding=1, bias=False),
    nn.BatchNorm2d(n_g_feature),
    nn.ReLU(),
    # 大小 = (64, 16, 16)
    nn.ConvTranspose2d(n_g_feature, n_channel, kernel_size=4, stride=2, padding=1),
    nn.Sigmoid(),
    # 图片大小 = (3, 32, 32)
)
# print(gnet)

# 搭建鉴别网络
n_d_feature = 64    # 鉴别网络隐藏层大小
dnet = nn.Sequential(
    # 图片大小 = (3, 32, 32)
    nn.Conv2d(n_channel, n_d_feature, kernel_size=4, stride=2, padding=1),
    nn.LeakyReLU(0.2),
    # 大小 = (64, 16, 16)
    nn.Conv2d(n_d_feature, 2*n_d_feature, kernel_size=4, stride=2, padding=1, bias=False),
    nn.BatchNorm2d(2*n_d_feature),
    nn.LeakyReLU(0.2),
    # 大小 = (256, 4, 4)
    nn.Conv2d(4*n_d_feature, 1, kernel_size=4),
    # 对数赔率张量大小 = (1, 1, 1)
)
# print(dnet)


# 定义用于初始化权重值的函数
def weights_init(m):
    if type(m) in [nn.ConvTranspose2d, nn.Conv2d]:
        init.xavier_normal_(m.weight)
    elif type(m) == nn.BatchNorm2d:
        init.normal_(m.weight, 1.0, 0.02)
        init.constant_(m.bias, 0)
# 生成网络和鉴别网络的初始化
gnet.apply(weights_init)
dnet.apply(weights_init)


# 训练生成网络和鉴别网络并输出图片（此代码需运行数小时）
import torch
import torch.optim

# 损失
criterion = nn.BCEWithLogitsLoss()
# 优化器
goptimizer = torch.optim.Adam(gnet.parameters(), lr=0.0002, betas=(0.5, 0.999))
doptimizer = torch.optim.Adam(dnet.parameters(), lr=0.0002, betas=(0.5, 0.999))
# 用于测试的固定噪声，用来查看相同的潜在张量在训练过程中生成图片的变换
batch_size = 64
fixed_noises = torch.randn(batch_size, latent_size, 1, 1)
# 训练过程
epoch_num = 10
for epoch in range(epoch_num):
    for batch_idx, data in enumerate(dataloader):
        # 载入本批次数据
        real_images, _ = data
        batch_size = real_images.size(0)


        # 训练鉴别网络
        labels = torch.ones(batch_size)  # 真实数据对应标签为1
        preds = dnet(real_images)        # 对真实数据进行判别
        outputs = preds.reshape(-1)
        dloss_real = criterion(outputs, labels)  # 真实数据的鉴别器损失
        dmean_real = outputs.sigmoid().mean()    # 计算鉴别器将多少比例的真实数据判定为真，仅用于输出显示

        noises = torch.randn(batch_size, latent_size, 1, 1)  # 潜在噪声
        fake_images = gnet(noises)          # 生成假数据
        labels = torch.zeros(batch_size)    # 假数据对应标签为0
        fake = fake_images.detach()     # 使得梯度的计算不回溯到生成网络，可用于加快训练速度。删去此步，结果不变
        preds = dnet(fake)                       # 对假数据进行鉴别
        outputs = preds.view(-1)
        dloss_fake = criterion(outputs, labels)  # 假数据的鉴别损失
        dmean_fake = outputs.sigmoid().mean()    # 计算鉴别器降多少比例的假数据判定为真，仅用于输出显示

        dloss = dloss_real + dloss_fake          # 总的鉴别器损失
        dnet.zero_grad()
        dloss.backward()
        doptimizer.step()


        # 训练生成网路
        labels = torch.ones(batch_size)     # 生成网络希望所有生成的数据都被认为是真数据
        preds = dnet(fake_images)           # 让假数据通过鉴别网络
        outputs = preds.view(-1)
        gloss = criterion(outputs, labels)  # 从真数据看到的损失
        gmean_fake = outputs.sigmoid().mean()  # 计算鉴别器将多少比例的假数据判定为真，仅用于输出显示
        gnet.zero_grad()
        gloss.backward()
        goptimizer.step()


        # 输出本步训练结果
        print('[{}/{}]'.format(epoch, epoch_num) +
              '[{}/{}]'.format(batch_idx, len(dataloader)) +
              '鉴别网络损失：{:g} 生成网络损失：{:g}'.format(dloss, gloss) +
              '真数据判真比例：{:g} 假数据判真比例：{:g}/{:g}'.format(dmean_real, dmean_fake, gmean_fake))
        if batch_idx % 100 == 0:
            fake = gnet(fixed_noises)
            save_image(fake, './data/images_epoch{:02d}_batch{:03d}.png'.format(epoch, batch_idx))
```

# 强化学习
当我们就某种外界状况做出正确的行为时，会获得一些奖励。我们会记住这样的经验，使得从外界刺激到行为的关联关系得到强化，以获得尽量大的奖励。

强化学习和普通监督学习的最大区别在于，监督学习知道训练数据的参考答案，而强化学习不知道训练数据的参考答案，只有奖励大小反馈。

强化学习和深度学习没有必然的联系。很多强化学习的过程并没有用到神经网络，但是也有许多强化学习的算法用到了神经网络。

```python
'''
	玩一局车杆游戏的代码
'''
import gym

env = gym.make('CartPile-v0')                     # 获得游戏环境，这个游戏环境可以被反复使用
observation = env.reset()                         # 复位游戏环境，新一局游戏开始
print('新一局游戏 初始观测 = {}'.format(observation))  # observation有4个分量，分别表示小车位置、小车速度、木棒角度和木棒角速度

for t in range(200):
    env.render()                                  # 在一个新的窗口上绘制当前的游戏状态，如果不想看图，就不必调用此函数(运行速度会更快)
    action = env.action_space.sample()            # 随机选择动作(0和1分别表示左移和右移)
    print('{}: 动作 = {}'.format(t, action))
    observation, reward, done, info = env.step(action)  # 执行行为(返回值分别表示观测、收益--总是为1、本局结束指示、其他信息)
    print('{}: 观测 {}, 本步得分 = {}, 结束指示 = {}, 其他信息 = {}'.format(t, observation, reward, done, info))
    if done:
        break
        
env.close()
```

```python
'''
	玩多局车杆游戏并统计每局得分
'''
import gym

env = gym.make('CartPole-v0')
n_episode = 20
for i_episode in range(n_episode):
    observation = env.reset()
    episode_reward = 0
    while True:
        # env.render()
        action = env.action_space.sample()
        observation, reward, done, _ = env.step(action)
        episode_reward += reward
        state = observation
    if done:
        break
    print('第{}局得分 = {}'.format(i_episode, episode_reward))
    
env.close()
```
上面玩家的动作都是随机选择的，所以枚举所得分数会很低。下面使用强化学习进行操作。

```python
import gym
import torch.nn as nn
import random
import torch
import math
import numpy as np
from collections import deque
import torch.optim


'''
1. 搭建一个三层全连接神经网络：
    隐藏层用ReLU层激活；
    网络的输入元素个数是观测的元素个数env.observation_space.shape[0]，总是为4；
    网络的输出元素个数是可能的行为个数eenv.action_space.n，总是为2。
'''
env = gym.make('CartPole-v0')
net = nn.Sequential(
    nn.Linear(env.observation_space.shape[0], 128),
    nn.ReLU(),
    nn.Linear(128, 128),
    nn.ReLU(),
    nn.Linear(128, env.action_space.n)
)


'''
2. 根据深度Q网络做决策：
    决策方法是epsilon贪心探索法。
    函数act()实现了epsilon贪心探索法，
    在函数内部，首先使用random.random()抽取一个[0,1]的随机数，
    如果这个随机数大于epsilon，那么就确定性地选使得q(s, a)最大的动作a，
    如果随机数小等于epsilon，则随机选择一种动作。
'''
def act(net, state, epsilon):
    if random.random() > epsilon:  # 选最大的
        state = torch.FloatTensor(state).unsqueeze(0)
        q_value = net.forward(state)
        action = q_value.max(1)[1].item()
    else:                          # 随便选
        action = random.randrange(env.action_space.n)
    return action


'''
3. 深度Q网络的训练：
    epsilon值随着训练步数不断变小（从1逐步减小到0.01）
'''
def calc_epsilon(t, epsilon_start=1.0, epsilon_final=0.01, epsilon_decay=500):
    epsilon = epsilon_final + (epsilon_start - epsilon_final) * math.exp(-1. * t / epsilon_decay)
    return epsilon

'''
4. 实现最近历史的缓存：
    定义ReplayBuffer类存储最近的历史，并在最近的历史中采样。
    该类内部有个大小有限的双端队列buffer，它可以不断存储新的历史，
    并且在满时自动删去最久远的历史。
'''
batch_size = 32

class ReplayBuffer(object):
    def __init__(self, capacity):
        self.buffer = deque(maxlen=capacity)

    def push(self, state, action, reward, next_state, done):
        state = np.expand_dims(state, 0)
        next_state = np.expand_dims(next_state, 0)
        self.buffer.append((state, action, reward, next_state, done))

    def sample(self, batch_size):
        state, action, reward, next_state, done = zip(*random.sample(self.buffer, batch_size))
        concat_state = np.concatenate(state)
        concat_next_state = np.concatenate(next_state)
        return concat_state, action, reward, concat_next_state, done

    def __len__(self):
        return len(self.buffer)

replay_buffer = ReplayBuffer(1000)


'''
5. 训练深度Q网络
'''
optimizer = torch.optim.Adam(net.parameters())
gamma = 0.99 # 折扣率
episode_rewards = []
t = 0

while True:
    # 开始新的一局
    state = env.reset()
    episode_reward = 0

    while True:
        epsilon = calc_epsilon(t)
        action = act(net, state, epsilon)
        next_state, reward, done, _ = env.step(action)
        replay_buffer.push(state, action, reward, next_state, done)

        state = next_state
        episode_reward += reward

        if len(replay_buffer) > batch_size:
            # 计算时间差分误差
            sample_state, sample_action, sample_reward, sample_next_state, sample_done = replay_buffer.sample(batch_size)

            sample_state = torch.tensor(sample_state, dtype=torch.float32)
            sample_action = torch.tensor(sample_action, dtype=torch.int64)
            sample_reward = torch.tensor(sample_reward, dtype=torch.float32)
            sample_next_state = torch.tensor(sample_next_state, dtype=torch.float32)
            sample_done = torch.tensor(sample_done, dtype=torch.float32)

            next_qs = net(sample_next_state)
            next_q, _ = next_qs.max(1)
            expected_q = sample_reward + gamma * next_q * (1 - sample_done)

            qs = net(sample_state)
            q = qs.gather(1, sample_action.unsqueeze(1)).squeeze(1)

            td_error = expected_q - q

            # 计算MSE损失
            loss = td_error.pow(2).mean()

            # 根据损失改进网络
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            t += 1

        if done:
            i_episode = len(episode_rewards)
            print('第{}局收益 = {}'.format(i_episode, episode_reward))
            episode_rewards.append(episode_reward)
            break

    if len(episode_rewards) > 20 and np.mean(episode_rewards[-20:]) > 195:
        break


'''
6. 使用游戏AI玩车杆游戏
'''
n_episode = 20
for i_episode in range(n_episode):
    observation = env.reset()
    episode_reward = 0
    while True:
        # env.render()
        action = act(net, observation, 0)
        observation, reward, done, _ = env.step(action)
        episode_reward += reward
        state = observation
        if done:
            break

    print(f'第{i_episode}局得分 = {episode_reward}')
```